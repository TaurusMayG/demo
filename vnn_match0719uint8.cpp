/****************************************************************************
*   Generated by ACUITY 5.24.6
*   Match ovxlib 1.1.31
*
*   Neural Network appliction network definition source file
****************************************************************************/
/*-------------------------------------------
                   Includes
 -------------------------------------------*/
#include <stdio.h>
#include <stdlib.h>

#include "vsi_nn_pub.h"

#include "vnn_global.h"
#include "vnn_match0719uint8.h"

/*-------------------------------------------
                   Macros
 -------------------------------------------*/

#define NEW_VXNODE(_node, _type, _in, _out, _uid) do {\
        _node = vsi_nn_AddNode( graph, _type, _in, _out, NULL );\
        if( NULL == _node ) {\
            goto error;\
        }\
        _node->uid = (uint32_t)_uid;\
    } while(0)

#define NEW_VIRTUAL_TENSOR(_id, _attr, _dtype) do {\
        memset( _attr.size, 0, VSI_NN_MAX_DIM_NUM * sizeof(uint32_t));\
        _attr.dim_num = VSI_NN_DIM_AUTO;\
        _attr.vtl = !VNN_APP_DEBUG;\
        _attr.is_const = FALSE;\
        _attr.dtype.vx_type = _dtype;\
        _id = vsi_nn_AddTensor( graph, VSI_NN_TENSOR_ID_AUTO,\
                & _attr, NULL );\
        if( VSI_NN_TENSOR_ID_NA == _id ) {\
            goto error;\
        }\
    } while(0)

// Set const tensor dims out of this macro.
#define NEW_CONST_TENSOR(_id, _attr, _dtype, _ofst, _size) do {\
        data = load_data( fp, _ofst, _size  );\
        _attr.vtl = FALSE;\
        _attr.is_const = TRUE;\
        _attr.dtype.vx_type = _dtype;\
        _id = vsi_nn_AddTensor( graph, VSI_NN_TENSOR_ID_AUTO,\
                & _attr, data );\
        free( data );\
        if( VSI_NN_TENSOR_ID_NA == _id ) {\
            goto error;\
        }\
    } while(0)

// Set generic tensor dims out of this macro.
#define NEW_NORM_TENSOR(_id, _attr, _dtype) do {\
        _attr.vtl = FALSE;\
        _attr.is_const = FALSE;\
        _attr.dtype.vx_type = _dtype;\
        _id = vsi_nn_AddTensor( graph, VSI_NN_TENSOR_ID_AUTO,\
                & _attr, NULL );\
        if( VSI_NN_TENSOR_ID_NA == _id ) {\
            goto error;\
        }\
    } while(0)

// Set generic tensor dims out of this macro.
#define NEW_NORM_TENSOR_FROM_HANDLE(_id, _attr, _dtype) do {\
        _attr.vtl = FALSE;\
        _attr.is_const = FALSE;\
        _attr.dtype.vx_type = _dtype;\
        _id = vsi_nn_AddTensorFromHandle( graph, VSI_NN_TENSOR_ID_AUTO,\
                & _attr, NULL );\
        if( VSI_NN_TENSOR_ID_NA == _id ) {\
            goto error;\
        }\
    } while(0)

#define NET_NODE_NUM            (125)
#define NET_NORM_TENSOR_NUM     (6)
#define NET_CONST_TENSOR_NUM    (89)
#define NET_VIRTUAL_TENSOR_NUM  (125)
#define NET_TOTAL_TENSOR_NUM    (NET_NORM_TENSOR_NUM + NET_CONST_TENSOR_NUM + NET_VIRTUAL_TENSOR_NUM)

/*-------------------------------------------
               Local Variables
 -------------------------------------------*/

/*-------------------------------------------
                  Functions
 -------------------------------------------*/
static uint8_t* load_data
    (
    FILE  * fp,
    size_t  ofst,
    size_t  sz
    )
{
    uint8_t* data;
    int32_t ret;
    data = NULL;
    if( NULL == fp )
    {
        return NULL;
    }

    ret = fseek(fp, ofst, SEEK_SET);
    if (ret != 0)
    {
        VSILOGE("blob seek failure.");
        return NULL;
    }

    data = (uint8_t*)malloc(sz);
    if (data == NULL)
    {
        VSILOGE("buffer malloc failure.");
        return NULL;
    }
    ret = fread(data, 1, sz, fp);
    return data;
} /* load_data() */

vsi_nn_graph_t * vnn_CreateMatch0719Uint8
    (
    const char * data_file_name,
    vsi_nn_context_t in_ctx,
    const vsi_nn_preprocess_map_element_t * pre_process_map,
    uint32_t pre_process_map_count,
    const vsi_nn_postprocess_map_element_t * post_process_map,
    uint32_t post_process_map_count
    )
{
    uint32_t                _infinity = VSI_NN_FLOAT32_INF;
    vsi_status              status;
    vsi_bool                release_ctx;
    vsi_nn_context_t        ctx;
    vsi_nn_graph_t *        graph;
    vsi_nn_node_t *         node[NET_NODE_NUM];
    vsi_nn_tensor_id_t      norm_tensor[NET_NORM_TENSOR_NUM];
    vsi_nn_tensor_id_t      const_tensor[NET_CONST_TENSOR_NUM];
    vsi_nn_tensor_attr_t    attr;
    FILE *                  fp;
    uint8_t *               data;
    uint32_t                i = 0;
    char *                  use_img_process_s;
    int32_t                 enable_pre_post_process = 0;
    vsi_bool                sort = FALSE;
    vsi_bool                inference_with_nbg = FALSE;
    char*                   pos = NULL;

    uint32_t   axis_1[] = { 2 };
    uint32_t   axis_2[] = { 2 };
    uint32_t   axis_3[] = { 2 };
    uint32_t   axis_4[] = { 2 };
    uint32_t   begin_1[] = { 0, 299, 0, 0 };
    uint32_t   begin_2[] = { 299, 0, 0, 0 };
    uint32_t   shape_1[] = { 512, 512, 1, 1 };
    uint32_t   shape_2[] = { 128, 128, 1, 1 };
    uint32_t   shape_3[] = { 200, 200, 1, 1 };
    uint32_t   shape_4[] = { 50, 50, 1, 1 };
    uint32_t   size_1[] = { 800, 200, 1, 1 };
    uint32_t   size_2[] = { 200, 200, 1, 1 };




    (void)(_infinity);
    ctx = NULL;
    graph = NULL;
    status = VSI_FAILURE;
    memset( &attr, 0, sizeof( attr ) );

    fp = fopen( data_file_name, "rb" );
    if( NULL == fp )
    {
        VSILOGE( "Open file %s failed.", data_file_name );
        goto error;
    }

    pos = strstr(data_file_name, ".nb");
    if( pos && strcmp(pos, ".nb") == 0 )
    {
        inference_with_nbg = TRUE;
    }

    if( NULL == in_ctx )
    {
        ctx = vsi_nn_CreateContext();
    }
    else
    {
        ctx = in_ctx;
    }

    use_img_process_s = getenv( "VSI_USE_IMAGE_PROCESS" );
    if( use_img_process_s )
    {
        enable_pre_post_process = atoi(use_img_process_s);
    }

    graph = vsi_nn_CreateGraph( ctx, NET_TOTAL_TENSOR_NUM, NET_NODE_NUM );
    if( NULL == graph )
    {
        VSILOGE( "Create graph fail." );
        goto error;
    }
    vsi_nn_SetGraphVersion( graph, VNN_VERSION_MAJOR, VNN_VERSION_MINOR, VNN_VERSION_PATCH );
    vsi_nn_SetGraphInputs( graph, NULL, 2 );
    vsi_nn_SetGraphOutputs( graph, NULL, 4 );

/*-----------------------------------------
  Register client ops
 -----------------------------------------*/


/*-----------------------------------------
  Node definitions
 -----------------------------------------*/
    if( !inference_with_nbg )
    {

    /*-----------------------------------------
      lid       - Initializer_217_53
      var       - node[0]
      name      - Initializer_217
      operation - variable
      input     - 
      output    - [1]
    -----------------------------------------*/
    NEW_VXNODE(node[0], VSI_NN_OP_VARIABLE, 1, 1, 53);

    /*-----------------------------------------
      lid       - Conv_Conv_10_80
      var       - node[1]
      name      - Conv_Conv_10
      operation - convolution
      input     - [512, 512, 1, 1]
      filter    - [3, 3, 1, 32]
      output    - [512, 512, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[1], VSI_NN_OP_CONV2D, 3, 1, 80);
    node[1]->nn_param.conv2d.ksize[0] = 3;
    node[1]->nn_param.conv2d.ksize[1] = 3;
    node[1]->nn_param.conv2d.weights = 32;
    node[1]->nn_param.conv2d.stride[0] = 1;
    node[1]->nn_param.conv2d.stride[1] = 1;
    node[1]->nn_param.conv2d.pad[0] = 1;
    node[1]->nn_param.conv2d.pad[1] = 1;
    node[1]->nn_param.conv2d.pad[2] = 1;
    node[1]->nn_param.conv2d.pad[3] = 1;
    node[1]->nn_param.conv2d.group = 1;
    node[1]->nn_param.conv2d.dilation[0] = 1;
    node[1]->nn_param.conv2d.dilation[1] = 1;
    node[1]->nn_param.conv2d.multiplier = 0;
    node[1]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[1]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[1]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - AveragePool_AveragePool_85_93
      var       - node[2]
      name      - AveragePool_AveragePool_85
      operation - pooling
      input     - [512, 512, 1, 1]
      output    - [128, 128, 1, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[2], VSI_NN_OP_POOL, 1, 1, 93);
    node[2]->nn_param.pool.ksize[0] = 4;
    node[2]->nn_param.pool.ksize[1] = 4;
    node[2]->nn_param.pool.stride[0] = 4;
    node[2]->nn_param.pool.stride[1] = 4;
    node[2]->nn_param.pool.pad[0] = 0;
    node[2]->nn_param.pool.pad[1] = 0;
    node[2]->nn_param.pool.pad[2] = 0;
    node[2]->nn_param.pool.pad[3] = 0;
    node[2]->nn_param.pool.type = VX_CONVOLUTIONAL_NETWORK_POOLING_AVG;
    node[2]->nn_param.pool.round_type = VSI_NN_ROUND_FLOOR;
    node[2]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Slice_Slice_4_106
      var       - node[3]
      name      - Slice_Slice_4
      operation - slice
      input     - [800, 800, 1, 1]
      output    - [800, 200, 1, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[3], VSI_NN_OP_SLICE, 1, 1, 106);
    node[3]->nn_param.slice.dims = 4;
    node[3]->nn_param.slice.start = begin_1;
    node[3]->nn_param.slice.length = size_1;

    /*-----------------------------------------
      lid       - LeakyRelu_LeakyRelu_11_57
      var       - node[4]
      name      - LeakyRelu_LeakyRelu_11
      operation - leakyrelu
      input     - [512, 512, 32, 1]
      output    - [512, 512, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[4], VSI_NN_OP_LEAKY_RELU, 1, 1, 57);
    node[4]->nn_param.activation.leaky_ratio = 0.009999999776482582;

    /*-----------------------------------------
      lid       - Conv_Conv_86_92
      var       - node[5]
      name      - Conv_Conv_86
      operation - convolution
      input     - [128, 128, 1, 1]
      filter    - [3, 3, 1, 32]
      output    - [128, 128, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[5], VSI_NN_OP_CONV2D, 3, 1, 92);
    node[5]->nn_param.conv2d.ksize[0] = 3;
    node[5]->nn_param.conv2d.ksize[1] = 3;
    node[5]->nn_param.conv2d.weights = 32;
    node[5]->nn_param.conv2d.stride[0] = 1;
    node[5]->nn_param.conv2d.stride[1] = 1;
    node[5]->nn_param.conv2d.pad[0] = 1;
    node[5]->nn_param.conv2d.pad[1] = 1;
    node[5]->nn_param.conv2d.pad[2] = 1;
    node[5]->nn_param.conv2d.pad[3] = 1;
    node[5]->nn_param.conv2d.group = 1;
    node[5]->nn_param.conv2d.dilation[0] = 1;
    node[5]->nn_param.conv2d.dilation[1] = 1;
    node[5]->nn_param.conv2d.multiplier = 0;
    node[5]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[5]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[5]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Slice_Slice_9_88
      var       - node[6]
      name      - Slice_Slice_9
      operation - slice
      input     - [800, 200, 1, 1]
      output    - [200, 200, 1, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[6], VSI_NN_OP_SLICE, 1, 1, 88);
    node[6]->nn_param.slice.dims = 4;
    node[6]->nn_param.slice.start = begin_2;
    node[6]->nn_param.slice.length = size_2;

    /*-----------------------------------------
      lid       - Conv_Conv_12_81
      var       - node[7]
      name      - Conv_Conv_12
      operation - convolution
      input     - [512, 512, 32, 1]
      filter    - [3, 3, 32, 32]
      output    - [512, 512, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[7], VSI_NN_OP_CONV2D, 3, 1, 81);
    node[7]->nn_param.conv2d.ksize[0] = 3;
    node[7]->nn_param.conv2d.ksize[1] = 3;
    node[7]->nn_param.conv2d.weights = 32;
    node[7]->nn_param.conv2d.stride[0] = 1;
    node[7]->nn_param.conv2d.stride[1] = 1;
    node[7]->nn_param.conv2d.pad[0] = 1;
    node[7]->nn_param.conv2d.pad[1] = 1;
    node[7]->nn_param.conv2d.pad[2] = 1;
    node[7]->nn_param.conv2d.pad[3] = 1;
    node[7]->nn_param.conv2d.group = 1;
    node[7]->nn_param.conv2d.dilation[0] = 1;
    node[7]->nn_param.conv2d.dilation[1] = 1;
    node[7]->nn_param.conv2d.multiplier = 0;
    node[7]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[7]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[7]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - LeakyRelu_LeakyRelu_87_69
      var       - node[8]
      name      - LeakyRelu_LeakyRelu_87
      operation - leakyrelu
      input     - [128, 128, 32, 1]
      output    - [128, 128, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[8], VSI_NN_OP_LEAKY_RELU, 1, 1, 69);
    node[8]->nn_param.activation.leaky_ratio = 0.009999999776482582;

    /*-----------------------------------------
      lid       - Conv_Conv_34_75
      var       - node[9]
      name      - Conv_Conv_34
      operation - convolution
      input     - [200, 200, 1, 1]
      filter    - [3, 3, 1, 32]
      output    - [200, 200, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[9], VSI_NN_OP_CONV2D, 3, 1, 75);
    node[9]->nn_param.conv2d.ksize[0] = 3;
    node[9]->nn_param.conv2d.ksize[1] = 3;
    node[9]->nn_param.conv2d.weights = 32;
    node[9]->nn_param.conv2d.stride[0] = 1;
    node[9]->nn_param.conv2d.stride[1] = 1;
    node[9]->nn_param.conv2d.pad[0] = 1;
    node[9]->nn_param.conv2d.pad[1] = 1;
    node[9]->nn_param.conv2d.pad[2] = 1;
    node[9]->nn_param.conv2d.pad[3] = 1;
    node[9]->nn_param.conv2d.group = 1;
    node[9]->nn_param.conv2d.dilation[0] = 1;
    node[9]->nn_param.conv2d.dilation[1] = 1;
    node[9]->nn_param.conv2d.multiplier = 0;
    node[9]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[9]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[9]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - AveragePool_AveragePool_82_87
      var       - node[10]
      name      - AveragePool_AveragePool_82
      operation - pooling
      input     - [200, 200, 1, 1]
      output    - [50, 50, 1, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[10], VSI_NN_OP_POOL, 1, 1, 87);
    node[10]->nn_param.pool.ksize[0] = 4;
    node[10]->nn_param.pool.ksize[1] = 4;
    node[10]->nn_param.pool.stride[0] = 4;
    node[10]->nn_param.pool.stride[1] = 4;
    node[10]->nn_param.pool.pad[0] = 0;
    node[10]->nn_param.pool.pad[1] = 0;
    node[10]->nn_param.pool.pad[2] = 0;
    node[10]->nn_param.pool.pad[3] = 0;
    node[10]->nn_param.pool.type = VX_CONVOLUTIONAL_NETWORK_POOLING_AVG;
    node[10]->nn_param.pool.round_type = VSI_NN_ROUND_FLOOR;
    node[10]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Relu_Relu_13_79
      var       - node[11]
      name      - Relu_Relu_13
      operation - relu
      input     - [512, 512, 32, 1]
      output    - [512, 512, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[11], VSI_NN_OP_RELU, 1, 1, 79);

    /*-----------------------------------------
      lid       - Conv_Conv_88_94
      var       - node[12]
      name      - Conv_Conv_88
      operation - convolution
      input     - [128, 128, 32, 1]
      filter    - [3, 3, 32, 32]
      output    - [128, 128, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[12], VSI_NN_OP_CONV2D, 3, 1, 94);
    node[12]->nn_param.conv2d.ksize[0] = 3;
    node[12]->nn_param.conv2d.ksize[1] = 3;
    node[12]->nn_param.conv2d.weights = 32;
    node[12]->nn_param.conv2d.stride[0] = 1;
    node[12]->nn_param.conv2d.stride[1] = 1;
    node[12]->nn_param.conv2d.pad[0] = 1;
    node[12]->nn_param.conv2d.pad[1] = 1;
    node[12]->nn_param.conv2d.pad[2] = 1;
    node[12]->nn_param.conv2d.pad[3] = 1;
    node[12]->nn_param.conv2d.group = 1;
    node[12]->nn_param.conv2d.dilation[0] = 1;
    node[12]->nn_param.conv2d.dilation[1] = 1;
    node[12]->nn_param.conv2d.multiplier = 0;
    node[12]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[12]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[12]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - LeakyRelu_LeakyRelu_35_51
      var       - node[13]
      name      - LeakyRelu_LeakyRelu_35
      operation - leakyrelu
      input     - [200, 200, 32, 1]
      output    - [200, 200, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[13], VSI_NN_OP_LEAKY_RELU, 1, 1, 51);
    node[13]->nn_param.activation.leaky_ratio = 0.009999999776482582;

    /*-----------------------------------------
      lid       - Conv_Conv_110_86
      var       - node[14]
      name      - Conv_Conv_110
      operation - convolution
      input     - [50, 50, 1, 1]
      filter    - [3, 3, 1, 32]
      output    - [50, 50, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[14], VSI_NN_OP_CONV2D, 3, 1, 86);
    node[14]->nn_param.conv2d.ksize[0] = 3;
    node[14]->nn_param.conv2d.ksize[1] = 3;
    node[14]->nn_param.conv2d.weights = 32;
    node[14]->nn_param.conv2d.stride[0] = 1;
    node[14]->nn_param.conv2d.stride[1] = 1;
    node[14]->nn_param.conv2d.pad[0] = 1;
    node[14]->nn_param.conv2d.pad[1] = 1;
    node[14]->nn_param.conv2d.pad[2] = 1;
    node[14]->nn_param.conv2d.pad[3] = 1;
    node[14]->nn_param.conv2d.group = 1;
    node[14]->nn_param.conv2d.dilation[0] = 1;
    node[14]->nn_param.conv2d.dilation[1] = 1;
    node[14]->nn_param.conv2d.multiplier = 0;
    node[14]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[14]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[14]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Conv_Conv_14_56
      var       - node[15]
      name      - Conv_Conv_14
      operation - convolution
      input     - [512, 512, 32, 1]
      filter    - [3, 3, 32, 32]
      output    - [512, 512, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[15], VSI_NN_OP_CONV2D, 3, 1, 56);
    node[15]->nn_param.conv2d.ksize[0] = 3;
    node[15]->nn_param.conv2d.ksize[1] = 3;
    node[15]->nn_param.conv2d.weights = 32;
    node[15]->nn_param.conv2d.stride[0] = 1;
    node[15]->nn_param.conv2d.stride[1] = 1;
    node[15]->nn_param.conv2d.pad[0] = 1;
    node[15]->nn_param.conv2d.pad[1] = 1;
    node[15]->nn_param.conv2d.pad[2] = 1;
    node[15]->nn_param.conv2d.pad[3] = 1;
    node[15]->nn_param.conv2d.group = 1;
    node[15]->nn_param.conv2d.dilation[0] = 1;
    node[15]->nn_param.conv2d.dilation[1] = 1;
    node[15]->nn_param.conv2d.multiplier = 0;
    node[15]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[15]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[15]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Relu_Relu_89_91
      var       - node[16]
      name      - Relu_Relu_89
      operation - relu
      input     - [128, 128, 32, 1]
      output    - [128, 128, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[16], VSI_NN_OP_RELU, 1, 1, 91);

    /*-----------------------------------------
      lid       - Conv_Conv_36_97
      var       - node[17]
      name      - Conv_Conv_36
      operation - convolution
      input     - [200, 200, 32, 1]
      filter    - [3, 3, 32, 32]
      output    - [200, 200, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[17], VSI_NN_OP_CONV2D, 3, 1, 97);
    node[17]->nn_param.conv2d.ksize[0] = 3;
    node[17]->nn_param.conv2d.ksize[1] = 3;
    node[17]->nn_param.conv2d.weights = 32;
    node[17]->nn_param.conv2d.stride[0] = 1;
    node[17]->nn_param.conv2d.stride[1] = 1;
    node[17]->nn_param.conv2d.pad[0] = 1;
    node[17]->nn_param.conv2d.pad[1] = 1;
    node[17]->nn_param.conv2d.pad[2] = 1;
    node[17]->nn_param.conv2d.pad[3] = 1;
    node[17]->nn_param.conv2d.group = 1;
    node[17]->nn_param.conv2d.dilation[0] = 1;
    node[17]->nn_param.conv2d.dilation[1] = 1;
    node[17]->nn_param.conv2d.multiplier = 0;
    node[17]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[17]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[17]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - LeakyRelu_LeakyRelu_111_63
      var       - node[18]
      name      - LeakyRelu_LeakyRelu_111
      operation - leakyrelu
      input     - [50, 50, 32, 1]
      output    - [50, 50, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[18], VSI_NN_OP_LEAKY_RELU, 1, 1, 63);
    node[18]->nn_param.activation.leaky_ratio = 0.009999999776482582;

    /*-----------------------------------------
      lid       - Add_Add_15_40
      var       - node[19]
      name      - Add_Add_15
      operation - add
      input     - [512, 512, 32, 1]
                  [512, 512, 32, 1]
      output    - [512, 512, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[19], VSI_NN_OP_ADD, 2, 1, 40);

    /*-----------------------------------------
      lid       - Conv_Conv_90_68
      var       - node[20]
      name      - Conv_Conv_90
      operation - convolution
      input     - [128, 128, 32, 1]
      filter    - [3, 3, 32, 32]
      output    - [128, 128, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[20], VSI_NN_OP_CONV2D, 3, 1, 68);
    node[20]->nn_param.conv2d.ksize[0] = 3;
    node[20]->nn_param.conv2d.ksize[1] = 3;
    node[20]->nn_param.conv2d.weights = 32;
    node[20]->nn_param.conv2d.stride[0] = 1;
    node[20]->nn_param.conv2d.stride[1] = 1;
    node[20]->nn_param.conv2d.pad[0] = 1;
    node[20]->nn_param.conv2d.pad[1] = 1;
    node[20]->nn_param.conv2d.pad[2] = 1;
    node[20]->nn_param.conv2d.pad[3] = 1;
    node[20]->nn_param.conv2d.group = 1;
    node[20]->nn_param.conv2d.dilation[0] = 1;
    node[20]->nn_param.conv2d.dilation[1] = 1;
    node[20]->nn_param.conv2d.multiplier = 0;
    node[20]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[20]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[20]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Relu_Relu_37_74
      var       - node[21]
      name      - Relu_Relu_37
      operation - relu
      input     - [200, 200, 32, 1]
      output    - [200, 200, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[21], VSI_NN_OP_RELU, 1, 1, 74);

    /*-----------------------------------------
      lid       - Conv_Conv_112_105
      var       - node[22]
      name      - Conv_Conv_112
      operation - convolution
      input     - [50, 50, 32, 1]
      filter    - [3, 3, 32, 32]
      output    - [50, 50, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[22], VSI_NN_OP_CONV2D, 3, 1, 105);
    node[22]->nn_param.conv2d.ksize[0] = 3;
    node[22]->nn_param.conv2d.ksize[1] = 3;
    node[22]->nn_param.conv2d.weights = 32;
    node[22]->nn_param.conv2d.stride[0] = 1;
    node[22]->nn_param.conv2d.stride[1] = 1;
    node[22]->nn_param.conv2d.pad[0] = 1;
    node[22]->nn_param.conv2d.pad[1] = 1;
    node[22]->nn_param.conv2d.pad[2] = 1;
    node[22]->nn_param.conv2d.pad[3] = 1;
    node[22]->nn_param.conv2d.group = 1;
    node[22]->nn_param.conv2d.dilation[0] = 1;
    node[22]->nn_param.conv2d.dilation[1] = 1;
    node[22]->nn_param.conv2d.multiplier = 0;
    node[22]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[22]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[22]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Relu_Relu_16_28
      var       - node[23]
      name      - Relu_Relu_16
      operation - relu
      input     - [512, 512, 32, 1]
      output    - [512, 512, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[23], VSI_NN_OP_RELU, 1, 1, 28);

    /*-----------------------------------------
      lid       - Add_Add_91_46
      var       - node[24]
      name      - Add_Add_91
      operation - add
      input     - [128, 128, 32, 1]
                  [128, 128, 32, 1]
      output    - [128, 128, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[24], VSI_NN_OP_ADD, 2, 1, 46);

    /*-----------------------------------------
      lid       - Conv_Conv_38_50
      var       - node[25]
      name      - Conv_Conv_38
      operation - convolution
      input     - [200, 200, 32, 1]
      filter    - [3, 3, 32, 32]
      output    - [200, 200, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[25], VSI_NN_OP_CONV2D, 3, 1, 50);
    node[25]->nn_param.conv2d.ksize[0] = 3;
    node[25]->nn_param.conv2d.ksize[1] = 3;
    node[25]->nn_param.conv2d.weights = 32;
    node[25]->nn_param.conv2d.stride[0] = 1;
    node[25]->nn_param.conv2d.stride[1] = 1;
    node[25]->nn_param.conv2d.pad[0] = 1;
    node[25]->nn_param.conv2d.pad[1] = 1;
    node[25]->nn_param.conv2d.pad[2] = 1;
    node[25]->nn_param.conv2d.pad[3] = 1;
    node[25]->nn_param.conv2d.group = 1;
    node[25]->nn_param.conv2d.dilation[0] = 1;
    node[25]->nn_param.conv2d.dilation[1] = 1;
    node[25]->nn_param.conv2d.multiplier = 0;
    node[25]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[25]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[25]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Relu_Relu_113_85
      var       - node[26]
      name      - Relu_Relu_113
      operation - relu
      input     - [50, 50, 32, 1]
      output    - [50, 50, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[26], VSI_NN_OP_RELU, 1, 1, 85);

    /*-----------------------------------------
      lid       - Conv_Conv_20_116
      var       - node[27]
      name      - Conv_Conv_20
      operation - convolution
      input     - [512, 512, 32, 1]
      filter    - [1, 1, 32, 48]
      output    - [512, 512, 48, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[27], VSI_NN_OP_CONV2D, 3, 1, 116);
    node[27]->nn_param.conv2d.ksize[0] = 1;
    node[27]->nn_param.conv2d.ksize[1] = 1;
    node[27]->nn_param.conv2d.weights = 48;
    node[27]->nn_param.conv2d.stride[0] = 1;
    node[27]->nn_param.conv2d.stride[1] = 1;
    node[27]->nn_param.conv2d.pad[0] = 0;
    node[27]->nn_param.conv2d.pad[1] = 0;
    node[27]->nn_param.conv2d.pad[2] = 0;
    node[27]->nn_param.conv2d.pad[3] = 0;
    node[27]->nn_param.conv2d.group = 1;
    node[27]->nn_param.conv2d.dilation[0] = 1;
    node[27]->nn_param.conv2d.dilation[1] = 1;
    node[27]->nn_param.conv2d.multiplier = 0;
    node[27]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[27]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[27]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Conv_Conv_17_130
      var       - node[28]
      name      - Conv_Conv_17
      operation - convolution
      input     - [512, 512, 32, 1]
      filter    - [3, 3, 32, 48]
      output    - [512, 512, 48, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[28], VSI_NN_OP_CONV2D, 3, 1, 130);
    node[28]->nn_param.conv2d.ksize[0] = 3;
    node[28]->nn_param.conv2d.ksize[1] = 3;
    node[28]->nn_param.conv2d.weights = 48;
    node[28]->nn_param.conv2d.stride[0] = 1;
    node[28]->nn_param.conv2d.stride[1] = 1;
    node[28]->nn_param.conv2d.pad[0] = 1;
    node[28]->nn_param.conv2d.pad[1] = 1;
    node[28]->nn_param.conv2d.pad[2] = 1;
    node[28]->nn_param.conv2d.pad[3] = 1;
    node[28]->nn_param.conv2d.group = 1;
    node[28]->nn_param.conv2d.dilation[0] = 1;
    node[28]->nn_param.conv2d.dilation[1] = 1;
    node[28]->nn_param.conv2d.multiplier = 0;
    node[28]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[28]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[28]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Relu_Relu_92_34
      var       - node[29]
      name      - Relu_Relu_92
      operation - relu
      input     - [128, 128, 32, 1]
      output    - [128, 128, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[29], VSI_NN_OP_RELU, 1, 1, 34);

    /*-----------------------------------------
      lid       - Add_Add_39_37
      var       - node[30]
      name      - Add_Add_39
      operation - add
      input     - [200, 200, 32, 1]
                  [200, 200, 32, 1]
      output    - [200, 200, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[30], VSI_NN_OP_ADD, 2, 1, 37);

    /*-----------------------------------------
      lid       - Conv_Conv_114_62
      var       - node[31]
      name      - Conv_Conv_114
      operation - convolution
      input     - [50, 50, 32, 1]
      filter    - [3, 3, 32, 32]
      output    - [50, 50, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[31], VSI_NN_OP_CONV2D, 3, 1, 62);
    node[31]->nn_param.conv2d.ksize[0] = 3;
    node[31]->nn_param.conv2d.ksize[1] = 3;
    node[31]->nn_param.conv2d.weights = 32;
    node[31]->nn_param.conv2d.stride[0] = 1;
    node[31]->nn_param.conv2d.stride[1] = 1;
    node[31]->nn_param.conv2d.pad[0] = 1;
    node[31]->nn_param.conv2d.pad[1] = 1;
    node[31]->nn_param.conv2d.pad[2] = 1;
    node[31]->nn_param.conv2d.pad[3] = 1;
    node[31]->nn_param.conv2d.group = 1;
    node[31]->nn_param.conv2d.dilation[0] = 1;
    node[31]->nn_param.conv2d.dilation[1] = 1;
    node[31]->nn_param.conv2d.multiplier = 0;
    node[31]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[31]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[31]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Relu_Relu_18_124
      var       - node[32]
      name      - Relu_Relu_18
      operation - relu
      input     - [512, 512, 48, 1]
      output    - [512, 512, 48, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[32], VSI_NN_OP_RELU, 1, 1, 124);

    /*-----------------------------------------
      lid       - Conv_Conv_96_128
      var       - node[33]
      name      - Conv_Conv_96
      operation - convolution
      input     - [128, 128, 32, 1]
      filter    - [1, 1, 32, 48]
      output    - [128, 128, 48, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[33], VSI_NN_OP_CONV2D, 3, 1, 128);
    node[33]->nn_param.conv2d.ksize[0] = 1;
    node[33]->nn_param.conv2d.ksize[1] = 1;
    node[33]->nn_param.conv2d.weights = 48;
    node[33]->nn_param.conv2d.stride[0] = 1;
    node[33]->nn_param.conv2d.stride[1] = 1;
    node[33]->nn_param.conv2d.pad[0] = 0;
    node[33]->nn_param.conv2d.pad[1] = 0;
    node[33]->nn_param.conv2d.pad[2] = 0;
    node[33]->nn_param.conv2d.pad[3] = 0;
    node[33]->nn_param.conv2d.group = 1;
    node[33]->nn_param.conv2d.dilation[0] = 1;
    node[33]->nn_param.conv2d.dilation[1] = 1;
    node[33]->nn_param.conv2d.multiplier = 0;
    node[33]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[33]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[33]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Conv_Conv_93_132
      var       - node[34]
      name      - Conv_Conv_93
      operation - convolution
      input     - [128, 128, 32, 1]
      filter    - [3, 3, 32, 48]
      output    - [128, 128, 48, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[34], VSI_NN_OP_CONV2D, 3, 1, 132);
    node[34]->nn_param.conv2d.ksize[0] = 3;
    node[34]->nn_param.conv2d.ksize[1] = 3;
    node[34]->nn_param.conv2d.weights = 48;
    node[34]->nn_param.conv2d.stride[0] = 1;
    node[34]->nn_param.conv2d.stride[1] = 1;
    node[34]->nn_param.conv2d.pad[0] = 1;
    node[34]->nn_param.conv2d.pad[1] = 1;
    node[34]->nn_param.conv2d.pad[2] = 1;
    node[34]->nn_param.conv2d.pad[3] = 1;
    node[34]->nn_param.conv2d.group = 1;
    node[34]->nn_param.conv2d.dilation[0] = 1;
    node[34]->nn_param.conv2d.dilation[1] = 1;
    node[34]->nn_param.conv2d.multiplier = 0;
    node[34]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[34]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[34]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Relu_Relu_40_25
      var       - node[35]
      name      - Relu_Relu_40
      operation - relu
      input     - [200, 200, 32, 1]
      output    - [200, 200, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[35], VSI_NN_OP_RELU, 1, 1, 25);

    /*-----------------------------------------
      lid       - Add_Add_115_43
      var       - node[36]
      name      - Add_Add_115
      operation - add
      input     - [50, 50, 32, 1]
                  [50, 50, 32, 1]
      output    - [50, 50, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[36], VSI_NN_OP_ADD, 2, 1, 43);

    /*-----------------------------------------
      lid       - Conv_Conv_19_123
      var       - node[37]
      name      - Conv_Conv_19
      operation - convolution
      input     - [512, 512, 48, 1]
      filter    - [3, 3, 48, 48]
      output    - [512, 512, 48, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[37], VSI_NN_OP_CONV2D, 3, 1, 123);
    node[37]->nn_param.conv2d.ksize[0] = 3;
    node[37]->nn_param.conv2d.ksize[1] = 3;
    node[37]->nn_param.conv2d.weights = 48;
    node[37]->nn_param.conv2d.stride[0] = 1;
    node[37]->nn_param.conv2d.stride[1] = 1;
    node[37]->nn_param.conv2d.pad[0] = 1;
    node[37]->nn_param.conv2d.pad[1] = 1;
    node[37]->nn_param.conv2d.pad[2] = 1;
    node[37]->nn_param.conv2d.pad[3] = 1;
    node[37]->nn_param.conv2d.group = 1;
    node[37]->nn_param.conv2d.dilation[0] = 1;
    node[37]->nn_param.conv2d.dilation[1] = 1;
    node[37]->nn_param.conv2d.multiplier = 0;
    node[37]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[37]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[37]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Relu_Relu_94_129
      var       - node[38]
      name      - Relu_Relu_94
      operation - relu
      input     - [128, 128, 48, 1]
      output    - [128, 128, 48, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[38], VSI_NN_OP_RELU, 1, 1, 129);

    /*-----------------------------------------
      lid       - Conv_Conv_44_112
      var       - node[39]
      name      - Conv_Conv_44
      operation - convolution
      input     - [200, 200, 32, 1]
      filter    - [1, 1, 32, 48]
      output    - [200, 200, 48, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[39], VSI_NN_OP_CONV2D, 3, 1, 112);
    node[39]->nn_param.conv2d.ksize[0] = 1;
    node[39]->nn_param.conv2d.ksize[1] = 1;
    node[39]->nn_param.conv2d.weights = 48;
    node[39]->nn_param.conv2d.stride[0] = 1;
    node[39]->nn_param.conv2d.stride[1] = 1;
    node[39]->nn_param.conv2d.pad[0] = 0;
    node[39]->nn_param.conv2d.pad[1] = 0;
    node[39]->nn_param.conv2d.pad[2] = 0;
    node[39]->nn_param.conv2d.pad[3] = 0;
    node[39]->nn_param.conv2d.group = 1;
    node[39]->nn_param.conv2d.dilation[0] = 1;
    node[39]->nn_param.conv2d.dilation[1] = 1;
    node[39]->nn_param.conv2d.multiplier = 0;
    node[39]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[39]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[39]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Conv_Conv_41_122
      var       - node[40]
      name      - Conv_Conv_41
      operation - convolution
      input     - [200, 200, 32, 1]
      filter    - [3, 3, 32, 48]
      output    - [200, 200, 48, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[40], VSI_NN_OP_CONV2D, 3, 1, 122);
    node[40]->nn_param.conv2d.ksize[0] = 3;
    node[40]->nn_param.conv2d.ksize[1] = 3;
    node[40]->nn_param.conv2d.weights = 48;
    node[40]->nn_param.conv2d.stride[0] = 1;
    node[40]->nn_param.conv2d.stride[1] = 1;
    node[40]->nn_param.conv2d.pad[0] = 1;
    node[40]->nn_param.conv2d.pad[1] = 1;
    node[40]->nn_param.conv2d.pad[2] = 1;
    node[40]->nn_param.conv2d.pad[3] = 1;
    node[40]->nn_param.conv2d.group = 1;
    node[40]->nn_param.conv2d.dilation[0] = 1;
    node[40]->nn_param.conv2d.dilation[1] = 1;
    node[40]->nn_param.conv2d.multiplier = 0;
    node[40]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[40]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[40]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Relu_Relu_116_31
      var       - node[41]
      name      - Relu_Relu_116
      operation - relu
      input     - [50, 50, 32, 1]
      output    - [50, 50, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[41], VSI_NN_OP_RELU, 1, 1, 31);

    /*-----------------------------------------
      lid       - Add_Add_21_115
      var       - node[42]
      name      - Add_Add_21
      operation - add
      input     - [512, 512, 48, 1]
                  [512, 512, 48, 1]
      output    - [512, 512, 48, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[42], VSI_NN_OP_ADD, 2, 1, 115);

    /*-----------------------------------------
      lid       - Conv_Conv_95_127
      var       - node[43]
      name      - Conv_Conv_95
      operation - convolution
      input     - [128, 128, 48, 1]
      filter    - [3, 3, 48, 48]
      output    - [128, 128, 48, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[43], VSI_NN_OP_CONV2D, 3, 1, 127);
    node[43]->nn_param.conv2d.ksize[0] = 3;
    node[43]->nn_param.conv2d.ksize[1] = 3;
    node[43]->nn_param.conv2d.weights = 48;
    node[43]->nn_param.conv2d.stride[0] = 1;
    node[43]->nn_param.conv2d.stride[1] = 1;
    node[43]->nn_param.conv2d.pad[0] = 1;
    node[43]->nn_param.conv2d.pad[1] = 1;
    node[43]->nn_param.conv2d.pad[2] = 1;
    node[43]->nn_param.conv2d.pad[3] = 1;
    node[43]->nn_param.conv2d.group = 1;
    node[43]->nn_param.conv2d.dilation[0] = 1;
    node[43]->nn_param.conv2d.dilation[1] = 1;
    node[43]->nn_param.conv2d.multiplier = 0;
    node[43]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[43]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[43]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Relu_Relu_42_113
      var       - node[44]
      name      - Relu_Relu_42
      operation - relu
      input     - [200, 200, 48, 1]
      output    - [200, 200, 48, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[44], VSI_NN_OP_RELU, 1, 1, 113);

    /*-----------------------------------------
      lid       - Conv_Conv_120_120
      var       - node[45]
      name      - Conv_Conv_120
      operation - convolution
      input     - [50, 50, 32, 1]
      filter    - [1, 1, 32, 48]
      output    - [50, 50, 48, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[45], VSI_NN_OP_CONV2D, 3, 1, 120);
    node[45]->nn_param.conv2d.ksize[0] = 1;
    node[45]->nn_param.conv2d.ksize[1] = 1;
    node[45]->nn_param.conv2d.weights = 48;
    node[45]->nn_param.conv2d.stride[0] = 1;
    node[45]->nn_param.conv2d.stride[1] = 1;
    node[45]->nn_param.conv2d.pad[0] = 0;
    node[45]->nn_param.conv2d.pad[1] = 0;
    node[45]->nn_param.conv2d.pad[2] = 0;
    node[45]->nn_param.conv2d.pad[3] = 0;
    node[45]->nn_param.conv2d.group = 1;
    node[45]->nn_param.conv2d.dilation[0] = 1;
    node[45]->nn_param.conv2d.dilation[1] = 1;
    node[45]->nn_param.conv2d.multiplier = 0;
    node[45]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[45]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[45]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Conv_Conv_117_131
      var       - node[46]
      name      - Conv_Conv_117
      operation - convolution
      input     - [50, 50, 32, 1]
      filter    - [3, 3, 32, 48]
      output    - [50, 50, 48, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[46], VSI_NN_OP_CONV2D, 3, 1, 131);
    node[46]->nn_param.conv2d.ksize[0] = 3;
    node[46]->nn_param.conv2d.ksize[1] = 3;
    node[46]->nn_param.conv2d.weights = 48;
    node[46]->nn_param.conv2d.stride[0] = 1;
    node[46]->nn_param.conv2d.stride[1] = 1;
    node[46]->nn_param.conv2d.pad[0] = 1;
    node[46]->nn_param.conv2d.pad[1] = 1;
    node[46]->nn_param.conv2d.pad[2] = 1;
    node[46]->nn_param.conv2d.pad[3] = 1;
    node[46]->nn_param.conv2d.group = 1;
    node[46]->nn_param.conv2d.dilation[0] = 1;
    node[46]->nn_param.conv2d.dilation[1] = 1;
    node[46]->nn_param.conv2d.multiplier = 0;
    node[46]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[46]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[46]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Relu_Relu_22_114
      var       - node[47]
      name      - Relu_Relu_22
      operation - relu
      input     - [512, 512, 48, 1]
      output    - [512, 512, 48, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[47], VSI_NN_OP_RELU, 1, 1, 114);

    /*-----------------------------------------
      lid       - Add_Add_97_121
      var       - node[48]
      name      - Add_Add_97
      operation - add
      input     - [128, 128, 48, 1]
                  [128, 128, 48, 1]
      output    - [128, 128, 48, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[48], VSI_NN_OP_ADD, 2, 1, 121);

    /*-----------------------------------------
      lid       - Conv_Conv_43_111
      var       - node[49]
      name      - Conv_Conv_43
      operation - convolution
      input     - [200, 200, 48, 1]
      filter    - [3, 3, 48, 48]
      output    - [200, 200, 48, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[49], VSI_NN_OP_CONV2D, 3, 1, 111);
    node[49]->nn_param.conv2d.ksize[0] = 3;
    node[49]->nn_param.conv2d.ksize[1] = 3;
    node[49]->nn_param.conv2d.weights = 48;
    node[49]->nn_param.conv2d.stride[0] = 1;
    node[49]->nn_param.conv2d.stride[1] = 1;
    node[49]->nn_param.conv2d.pad[0] = 1;
    node[49]->nn_param.conv2d.pad[1] = 1;
    node[49]->nn_param.conv2d.pad[2] = 1;
    node[49]->nn_param.conv2d.pad[3] = 1;
    node[49]->nn_param.conv2d.group = 1;
    node[49]->nn_param.conv2d.dilation[0] = 1;
    node[49]->nn_param.conv2d.dilation[1] = 1;
    node[49]->nn_param.conv2d.multiplier = 0;
    node[49]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[49]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[49]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Relu_Relu_118_126
      var       - node[50]
      name      - Relu_Relu_118
      operation - relu
      input     - [50, 50, 48, 1]
      output    - [50, 50, 48, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[50], VSI_NN_OP_RELU, 1, 1, 126);

    /*-----------------------------------------
      lid       - Concat_Concat_23_102
      var       - node[51]
      name      - Concat_Concat_23
      operation - concat
      input     - [512, 512, 48, 1]
                  [512, 512, 32, 1]
      output    - [512, 512, 80, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[51], VSI_NN_OP_CONCAT, 2, 1, 102);
    node[51]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - Relu_Relu_98_110
      var       - node[52]
      name      - Relu_Relu_98
      operation - relu
      input     - [128, 128, 48, 1]
      output    - [128, 128, 48, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[52], VSI_NN_OP_RELU, 1, 1, 110);

    /*-----------------------------------------
      lid       - Add_Add_45_100
      var       - node[53]
      name      - Add_Add_45
      operation - add
      input     - [200, 200, 48, 1]
                  [200, 200, 48, 1]
      output    - [200, 200, 48, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[53], VSI_NN_OP_ADD, 2, 1, 100);

    /*-----------------------------------------
      lid       - Conv_Conv_119_125
      var       - node[54]
      name      - Conv_Conv_119
      operation - convolution
      input     - [50, 50, 48, 1]
      filter    - [3, 3, 48, 48]
      output    - [50, 50, 48, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[54], VSI_NN_OP_CONV2D, 3, 1, 125);
    node[54]->nn_param.conv2d.ksize[0] = 3;
    node[54]->nn_param.conv2d.ksize[1] = 3;
    node[54]->nn_param.conv2d.weights = 48;
    node[54]->nn_param.conv2d.stride[0] = 1;
    node[54]->nn_param.conv2d.stride[1] = 1;
    node[54]->nn_param.conv2d.pad[0] = 1;
    node[54]->nn_param.conv2d.pad[1] = 1;
    node[54]->nn_param.conv2d.pad[2] = 1;
    node[54]->nn_param.conv2d.pad[3] = 1;
    node[54]->nn_param.conv2d.group = 1;
    node[54]->nn_param.conv2d.dilation[0] = 1;
    node[54]->nn_param.conv2d.dilation[1] = 1;
    node[54]->nn_param.conv2d.multiplier = 0;
    node[54]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[54]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[54]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Conv_Conv_24_82
      var       - node[55]
      name      - Conv_Conv_24
      operation - convolution
      input     - [512, 512, 80, 1]
      filter    - [1, 1, 80, 48]
      output    - [512, 512, 48, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[55], VSI_NN_OP_CONV2D, 3, 1, 82);
    node[55]->nn_param.conv2d.ksize[0] = 1;
    node[55]->nn_param.conv2d.ksize[1] = 1;
    node[55]->nn_param.conv2d.weights = 48;
    node[55]->nn_param.conv2d.stride[0] = 1;
    node[55]->nn_param.conv2d.stride[1] = 1;
    node[55]->nn_param.conv2d.pad[0] = 0;
    node[55]->nn_param.conv2d.pad[1] = 0;
    node[55]->nn_param.conv2d.pad[2] = 0;
    node[55]->nn_param.conv2d.pad[3] = 0;
    node[55]->nn_param.conv2d.group = 1;
    node[55]->nn_param.conv2d.dilation[0] = 1;
    node[55]->nn_param.conv2d.dilation[1] = 1;
    node[55]->nn_param.conv2d.multiplier = 0;
    node[55]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[55]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[55]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Concat_Concat_99_109
      var       - node[56]
      name      - Concat_Concat_99
      operation - concat
      input     - [128, 128, 48, 1]
                  [128, 128, 32, 1]
      output    - [128, 128, 80, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[56], VSI_NN_OP_CONCAT, 2, 1, 109);
    node[56]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - Relu_Relu_46_99
      var       - node[57]
      name      - Relu_Relu_46
      operation - relu
      input     - [200, 200, 48, 1]
      output    - [200, 200, 48, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[57], VSI_NN_OP_RELU, 1, 1, 99);

    /*-----------------------------------------
      lid       - Add_Add_121_119
      var       - node[58]
      name      - Add_Add_121
      operation - add
      input     - [50, 50, 48, 1]
                  [50, 50, 48, 1]
      output    - [50, 50, 48, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[58], VSI_NN_OP_ADD, 2, 1, 119);

    /*-----------------------------------------
      lid       - LeakyRelu_LeakyRelu_25_78
      var       - node[59]
      name      - LeakyRelu_LeakyRelu_25
      operation - leakyrelu
      input     - [512, 512, 48, 1]
      output    - [512, 512, 48, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[59], VSI_NN_OP_LEAKY_RELU, 1, 1, 78);
    node[59]->nn_param.activation.leaky_ratio = 0.009999999776482582;

    /*-----------------------------------------
      lid       - Conv_Conv_100_108
      var       - node[60]
      name      - Conv_Conv_100
      operation - convolution
      input     - [128, 128, 80, 1]
      filter    - [1, 1, 80, 48]
      output    - [128, 128, 48, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[60], VSI_NN_OP_CONV2D, 3, 1, 108);
    node[60]->nn_param.conv2d.ksize[0] = 1;
    node[60]->nn_param.conv2d.ksize[1] = 1;
    node[60]->nn_param.conv2d.weights = 48;
    node[60]->nn_param.conv2d.stride[0] = 1;
    node[60]->nn_param.conv2d.stride[1] = 1;
    node[60]->nn_param.conv2d.pad[0] = 0;
    node[60]->nn_param.conv2d.pad[1] = 0;
    node[60]->nn_param.conv2d.pad[2] = 0;
    node[60]->nn_param.conv2d.pad[3] = 0;
    node[60]->nn_param.conv2d.group = 1;
    node[60]->nn_param.conv2d.dilation[0] = 1;
    node[60]->nn_param.conv2d.dilation[1] = 1;
    node[60]->nn_param.conv2d.multiplier = 0;
    node[60]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[60]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[60]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Concat_Concat_47_98
      var       - node[61]
      name      - Concat_Concat_47
      operation - concat
      input     - [200, 200, 48, 1]
                  [200, 200, 32, 1]
      output    - [200, 200, 80, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[61], VSI_NN_OP_CONCAT, 2, 1, 98);
    node[61]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - Relu_Relu_122_118
      var       - node[62]
      name      - Relu_Relu_122
      operation - relu
      input     - [50, 50, 48, 1]
      output    - [50, 50, 48, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[62], VSI_NN_OP_RELU, 1, 1, 118);

    /*-----------------------------------------
      lid       - Conv_Conv_29_55
      var       - node[63]
      name      - Conv_Conv_29
      operation - convolution
      input     - [512, 512, 48, 1]
      filter    - [1, 1, 48, 64]
      output    - [512, 512, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[63], VSI_NN_OP_CONV2D, 3, 1, 55);
    node[63]->nn_param.conv2d.ksize[0] = 1;
    node[63]->nn_param.conv2d.ksize[1] = 1;
    node[63]->nn_param.conv2d.weights = 64;
    node[63]->nn_param.conv2d.stride[0] = 1;
    node[63]->nn_param.conv2d.stride[1] = 1;
    node[63]->nn_param.conv2d.pad[0] = 0;
    node[63]->nn_param.conv2d.pad[1] = 0;
    node[63]->nn_param.conv2d.pad[2] = 0;
    node[63]->nn_param.conv2d.pad[3] = 0;
    node[63]->nn_param.conv2d.group = 1;
    node[63]->nn_param.conv2d.dilation[0] = 1;
    node[63]->nn_param.conv2d.dilation[1] = 1;
    node[63]->nn_param.conv2d.multiplier = 0;
    node[63]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[63]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[63]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Conv_Conv_26_101
      var       - node[64]
      name      - Conv_Conv_26
      operation - convolution
      input     - [512, 512, 48, 1]
      filter    - [3, 3, 48, 64]
      output    - [512, 512, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[64], VSI_NN_OP_CONV2D, 3, 1, 101);
    node[64]->nn_param.conv2d.ksize[0] = 3;
    node[64]->nn_param.conv2d.ksize[1] = 3;
    node[64]->nn_param.conv2d.weights = 64;
    node[64]->nn_param.conv2d.stride[0] = 1;
    node[64]->nn_param.conv2d.stride[1] = 1;
    node[64]->nn_param.conv2d.pad[0] = 1;
    node[64]->nn_param.conv2d.pad[1] = 1;
    node[64]->nn_param.conv2d.pad[2] = 1;
    node[64]->nn_param.conv2d.pad[3] = 1;
    node[64]->nn_param.conv2d.group = 1;
    node[64]->nn_param.conv2d.dilation[0] = 1;
    node[64]->nn_param.conv2d.dilation[1] = 1;
    node[64]->nn_param.conv2d.multiplier = 0;
    node[64]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[64]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[64]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - LeakyRelu_LeakyRelu_101_90
      var       - node[65]
      name      - LeakyRelu_LeakyRelu_101
      operation - leakyrelu
      input     - [128, 128, 48, 1]
      output    - [128, 128, 48, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[65], VSI_NN_OP_LEAKY_RELU, 1, 1, 90);
    node[65]->nn_param.activation.leaky_ratio = 0.009999999776482582;

    /*-----------------------------------------
      lid       - Conv_Conv_48_96
      var       - node[66]
      name      - Conv_Conv_48
      operation - convolution
      input     - [200, 200, 80, 1]
      filter    - [1, 1, 80, 48]
      output    - [200, 200, 48, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[66], VSI_NN_OP_CONV2D, 3, 1, 96);
    node[66]->nn_param.conv2d.ksize[0] = 1;
    node[66]->nn_param.conv2d.ksize[1] = 1;
    node[66]->nn_param.conv2d.weights = 48;
    node[66]->nn_param.conv2d.stride[0] = 1;
    node[66]->nn_param.conv2d.stride[1] = 1;
    node[66]->nn_param.conv2d.pad[0] = 0;
    node[66]->nn_param.conv2d.pad[1] = 0;
    node[66]->nn_param.conv2d.pad[2] = 0;
    node[66]->nn_param.conv2d.pad[3] = 0;
    node[66]->nn_param.conv2d.group = 1;
    node[66]->nn_param.conv2d.dilation[0] = 1;
    node[66]->nn_param.conv2d.dilation[1] = 1;
    node[66]->nn_param.conv2d.multiplier = 0;
    node[66]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[66]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[66]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Concat_Concat_123_117
      var       - node[67]
      name      - Concat_Concat_123
      operation - concat
      input     - [50, 50, 48, 1]
                  [50, 50, 32, 1]
      output    - [50, 50, 80, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[67], VSI_NN_OP_CONCAT, 2, 1, 117);
    node[67]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - Relu_Relu_27_77
      var       - node[68]
      name      - Relu_Relu_27
      operation - relu
      input     - [512, 512, 64, 1]
      output    - [512, 512, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[68], VSI_NN_OP_RELU, 1, 1, 77);

    /*-----------------------------------------
      lid       - Conv_Conv_105_67
      var       - node[69]
      name      - Conv_Conv_105
      operation - convolution
      input     - [128, 128, 48, 1]
      filter    - [1, 1, 48, 64]
      output    - [128, 128, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[69], VSI_NN_OP_CONV2D, 3, 1, 67);
    node[69]->nn_param.conv2d.ksize[0] = 1;
    node[69]->nn_param.conv2d.ksize[1] = 1;
    node[69]->nn_param.conv2d.weights = 64;
    node[69]->nn_param.conv2d.stride[0] = 1;
    node[69]->nn_param.conv2d.stride[1] = 1;
    node[69]->nn_param.conv2d.pad[0] = 0;
    node[69]->nn_param.conv2d.pad[1] = 0;
    node[69]->nn_param.conv2d.pad[2] = 0;
    node[69]->nn_param.conv2d.pad[3] = 0;
    node[69]->nn_param.conv2d.group = 1;
    node[69]->nn_param.conv2d.dilation[0] = 1;
    node[69]->nn_param.conv2d.dilation[1] = 1;
    node[69]->nn_param.conv2d.multiplier = 0;
    node[69]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[69]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[69]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Conv_Conv_102_107
      var       - node[70]
      name      - Conv_Conv_102
      operation - convolution
      input     - [128, 128, 48, 1]
      filter    - [3, 3, 48, 64]
      output    - [128, 128, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[70], VSI_NN_OP_CONV2D, 3, 1, 107);
    node[70]->nn_param.conv2d.ksize[0] = 3;
    node[70]->nn_param.conv2d.ksize[1] = 3;
    node[70]->nn_param.conv2d.weights = 64;
    node[70]->nn_param.conv2d.stride[0] = 1;
    node[70]->nn_param.conv2d.stride[1] = 1;
    node[70]->nn_param.conv2d.pad[0] = 1;
    node[70]->nn_param.conv2d.pad[1] = 1;
    node[70]->nn_param.conv2d.pad[2] = 1;
    node[70]->nn_param.conv2d.pad[3] = 1;
    node[70]->nn_param.conv2d.group = 1;
    node[70]->nn_param.conv2d.dilation[0] = 1;
    node[70]->nn_param.conv2d.dilation[1] = 1;
    node[70]->nn_param.conv2d.multiplier = 0;
    node[70]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[70]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[70]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - LeakyRelu_LeakyRelu_49_73
      var       - node[71]
      name      - LeakyRelu_LeakyRelu_49
      operation - leakyrelu
      input     - [200, 200, 48, 1]
      output    - [200, 200, 48, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[71], VSI_NN_OP_LEAKY_RELU, 1, 1, 73);
    node[71]->nn_param.activation.leaky_ratio = 0.009999999776482582;

    /*-----------------------------------------
      lid       - Conv_Conv_124_104
      var       - node[72]
      name      - Conv_Conv_124
      operation - convolution
      input     - [50, 50, 80, 1]
      filter    - [1, 1, 80, 48]
      output    - [50, 50, 48, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[72], VSI_NN_OP_CONV2D, 3, 1, 104);
    node[72]->nn_param.conv2d.ksize[0] = 1;
    node[72]->nn_param.conv2d.ksize[1] = 1;
    node[72]->nn_param.conv2d.weights = 48;
    node[72]->nn_param.conv2d.stride[0] = 1;
    node[72]->nn_param.conv2d.stride[1] = 1;
    node[72]->nn_param.conv2d.pad[0] = 0;
    node[72]->nn_param.conv2d.pad[1] = 0;
    node[72]->nn_param.conv2d.pad[2] = 0;
    node[72]->nn_param.conv2d.pad[3] = 0;
    node[72]->nn_param.conv2d.group = 1;
    node[72]->nn_param.conv2d.dilation[0] = 1;
    node[72]->nn_param.conv2d.dilation[1] = 1;
    node[72]->nn_param.conv2d.multiplier = 0;
    node[72]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[72]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[72]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Conv_Conv_28_54
      var       - node[73]
      name      - Conv_Conv_28
      operation - convolution
      input     - [512, 512, 64, 1]
      filter    - [3, 3, 64, 64]
      output    - [512, 512, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[73], VSI_NN_OP_CONV2D, 3, 1, 54);
    node[73]->nn_param.conv2d.ksize[0] = 3;
    node[73]->nn_param.conv2d.ksize[1] = 3;
    node[73]->nn_param.conv2d.weights = 64;
    node[73]->nn_param.conv2d.stride[0] = 1;
    node[73]->nn_param.conv2d.stride[1] = 1;
    node[73]->nn_param.conv2d.pad[0] = 1;
    node[73]->nn_param.conv2d.pad[1] = 1;
    node[73]->nn_param.conv2d.pad[2] = 1;
    node[73]->nn_param.conv2d.pad[3] = 1;
    node[73]->nn_param.conv2d.group = 1;
    node[73]->nn_param.conv2d.dilation[0] = 1;
    node[73]->nn_param.conv2d.dilation[1] = 1;
    node[73]->nn_param.conv2d.multiplier = 0;
    node[73]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[73]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[73]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Relu_Relu_103_89
      var       - node[74]
      name      - Relu_Relu_103
      operation - relu
      input     - [128, 128, 64, 1]
      output    - [128, 128, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[74], VSI_NN_OP_RELU, 1, 1, 89);

    /*-----------------------------------------
      lid       - Conv_Conv_53_49
      var       - node[75]
      name      - Conv_Conv_53
      operation - convolution
      input     - [200, 200, 48, 1]
      filter    - [1, 1, 48, 64]
      output    - [200, 200, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[75], VSI_NN_OP_CONV2D, 3, 1, 49);
    node[75]->nn_param.conv2d.ksize[0] = 1;
    node[75]->nn_param.conv2d.ksize[1] = 1;
    node[75]->nn_param.conv2d.weights = 64;
    node[75]->nn_param.conv2d.stride[0] = 1;
    node[75]->nn_param.conv2d.stride[1] = 1;
    node[75]->nn_param.conv2d.pad[0] = 0;
    node[75]->nn_param.conv2d.pad[1] = 0;
    node[75]->nn_param.conv2d.pad[2] = 0;
    node[75]->nn_param.conv2d.pad[3] = 0;
    node[75]->nn_param.conv2d.group = 1;
    node[75]->nn_param.conv2d.dilation[0] = 1;
    node[75]->nn_param.conv2d.dilation[1] = 1;
    node[75]->nn_param.conv2d.multiplier = 0;
    node[75]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[75]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[75]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Conv_Conv_50_95
      var       - node[76]
      name      - Conv_Conv_50
      operation - convolution
      input     - [200, 200, 48, 1]
      filter    - [3, 3, 48, 64]
      output    - [200, 200, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[76], VSI_NN_OP_CONV2D, 3, 1, 95);
    node[76]->nn_param.conv2d.ksize[0] = 3;
    node[76]->nn_param.conv2d.ksize[1] = 3;
    node[76]->nn_param.conv2d.weights = 64;
    node[76]->nn_param.conv2d.stride[0] = 1;
    node[76]->nn_param.conv2d.stride[1] = 1;
    node[76]->nn_param.conv2d.pad[0] = 1;
    node[76]->nn_param.conv2d.pad[1] = 1;
    node[76]->nn_param.conv2d.pad[2] = 1;
    node[76]->nn_param.conv2d.pad[3] = 1;
    node[76]->nn_param.conv2d.group = 1;
    node[76]->nn_param.conv2d.dilation[0] = 1;
    node[76]->nn_param.conv2d.dilation[1] = 1;
    node[76]->nn_param.conv2d.multiplier = 0;
    node[76]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[76]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[76]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - LeakyRelu_LeakyRelu_125_84
      var       - node[77]
      name      - LeakyRelu_LeakyRelu_125
      operation - leakyrelu
      input     - [50, 50, 48, 1]
      output    - [50, 50, 48, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[77], VSI_NN_OP_LEAKY_RELU, 1, 1, 84);
    node[77]->nn_param.activation.leaky_ratio = 0.009999999776482582;

    /*-----------------------------------------
      lid       - Add_Add_30_39
      var       - node[78]
      name      - Add_Add_30
      operation - add
      input     - [512, 512, 64, 1]
                  [512, 512, 64, 1]
      output    - [512, 512, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[78], VSI_NN_OP_ADD, 2, 1, 39);

    /*-----------------------------------------
      lid       - Conv_Conv_104_66
      var       - node[79]
      name      - Conv_Conv_104
      operation - convolution
      input     - [128, 128, 64, 1]
      filter    - [3, 3, 64, 64]
      output    - [128, 128, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[79], VSI_NN_OP_CONV2D, 3, 1, 66);
    node[79]->nn_param.conv2d.ksize[0] = 3;
    node[79]->nn_param.conv2d.ksize[1] = 3;
    node[79]->nn_param.conv2d.weights = 64;
    node[79]->nn_param.conv2d.stride[0] = 1;
    node[79]->nn_param.conv2d.stride[1] = 1;
    node[79]->nn_param.conv2d.pad[0] = 1;
    node[79]->nn_param.conv2d.pad[1] = 1;
    node[79]->nn_param.conv2d.pad[2] = 1;
    node[79]->nn_param.conv2d.pad[3] = 1;
    node[79]->nn_param.conv2d.group = 1;
    node[79]->nn_param.conv2d.dilation[0] = 1;
    node[79]->nn_param.conv2d.dilation[1] = 1;
    node[79]->nn_param.conv2d.multiplier = 0;
    node[79]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[79]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[79]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Relu_Relu_51_72
      var       - node[80]
      name      - Relu_Relu_51
      operation - relu
      input     - [200, 200, 64, 1]
      output    - [200, 200, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[80], VSI_NN_OP_RELU, 1, 1, 72);

    /*-----------------------------------------
      lid       - Conv_Conv_129_61
      var       - node[81]
      name      - Conv_Conv_129
      operation - convolution
      input     - [50, 50, 48, 1]
      filter    - [1, 1, 48, 64]
      output    - [50, 50, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[81], VSI_NN_OP_CONV2D, 3, 1, 61);
    node[81]->nn_param.conv2d.ksize[0] = 1;
    node[81]->nn_param.conv2d.ksize[1] = 1;
    node[81]->nn_param.conv2d.weights = 64;
    node[81]->nn_param.conv2d.stride[0] = 1;
    node[81]->nn_param.conv2d.stride[1] = 1;
    node[81]->nn_param.conv2d.pad[0] = 0;
    node[81]->nn_param.conv2d.pad[1] = 0;
    node[81]->nn_param.conv2d.pad[2] = 0;
    node[81]->nn_param.conv2d.pad[3] = 0;
    node[81]->nn_param.conv2d.group = 1;
    node[81]->nn_param.conv2d.dilation[0] = 1;
    node[81]->nn_param.conv2d.dilation[1] = 1;
    node[81]->nn_param.conv2d.multiplier = 0;
    node[81]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[81]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[81]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Conv_Conv_126_103
      var       - node[82]
      name      - Conv_Conv_126
      operation - convolution
      input     - [50, 50, 48, 1]
      filter    - [3, 3, 48, 64]
      output    - [50, 50, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[82], VSI_NN_OP_CONV2D, 3, 1, 103);
    node[82]->nn_param.conv2d.ksize[0] = 3;
    node[82]->nn_param.conv2d.ksize[1] = 3;
    node[82]->nn_param.conv2d.weights = 64;
    node[82]->nn_param.conv2d.stride[0] = 1;
    node[82]->nn_param.conv2d.stride[1] = 1;
    node[82]->nn_param.conv2d.pad[0] = 1;
    node[82]->nn_param.conv2d.pad[1] = 1;
    node[82]->nn_param.conv2d.pad[2] = 1;
    node[82]->nn_param.conv2d.pad[3] = 1;
    node[82]->nn_param.conv2d.group = 1;
    node[82]->nn_param.conv2d.dilation[0] = 1;
    node[82]->nn_param.conv2d.dilation[1] = 1;
    node[82]->nn_param.conv2d.multiplier = 0;
    node[82]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[82]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[82]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Relu_Relu_31_27
      var       - node[83]
      name      - Relu_Relu_31
      operation - relu
      input     - [512, 512, 64, 1]
      output    - [512, 512, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[83], VSI_NN_OP_RELU, 1, 1, 27);

    /*-----------------------------------------
      lid       - Add_Add_106_45
      var       - node[84]
      name      - Add_Add_106
      operation - add
      input     - [128, 128, 64, 1]
                  [128, 128, 64, 1]
      output    - [128, 128, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[84], VSI_NN_OP_ADD, 2, 1, 45);

    /*-----------------------------------------
      lid       - Conv_Conv_52_48
      var       - node[85]
      name      - Conv_Conv_52
      operation - convolution
      input     - [200, 200, 64, 1]
      filter    - [3, 3, 64, 64]
      output    - [200, 200, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[85], VSI_NN_OP_CONV2D, 3, 1, 48);
    node[85]->nn_param.conv2d.ksize[0] = 3;
    node[85]->nn_param.conv2d.ksize[1] = 3;
    node[85]->nn_param.conv2d.weights = 64;
    node[85]->nn_param.conv2d.stride[0] = 1;
    node[85]->nn_param.conv2d.stride[1] = 1;
    node[85]->nn_param.conv2d.pad[0] = 1;
    node[85]->nn_param.conv2d.pad[1] = 1;
    node[85]->nn_param.conv2d.pad[2] = 1;
    node[85]->nn_param.conv2d.pad[3] = 1;
    node[85]->nn_param.conv2d.group = 1;
    node[85]->nn_param.conv2d.dilation[0] = 1;
    node[85]->nn_param.conv2d.dilation[1] = 1;
    node[85]->nn_param.conv2d.multiplier = 0;
    node[85]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[85]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[85]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Relu_Relu_127_83
      var       - node[86]
      name      - Relu_Relu_127
      operation - relu
      input     - [50, 50, 64, 1]
      output    - [50, 50, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[86], VSI_NN_OP_RELU, 1, 1, 83);

    /*-----------------------------------------
      lid       - Concat_Concat_32_18
      var       - node[87]
      name      - Concat_Concat_32
      operation - concat
      input     - [512, 512, 64, 1]
                  [512, 512, 32, 1]
      output    - [512, 512, 96, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[87], VSI_NN_OP_CONCAT, 2, 1, 18);
    node[87]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - Relu_Relu_107_33
      var       - node[88]
      name      - Relu_Relu_107
      operation - relu
      input     - [128, 128, 64, 1]
      output    - [128, 128, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[88], VSI_NN_OP_RELU, 1, 1, 33);

    /*-----------------------------------------
      lid       - Add_Add_54_36
      var       - node[89]
      name      - Add_Add_54
      operation - add
      input     - [200, 200, 64, 1]
                  [200, 200, 64, 1]
      output    - [200, 200, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[89], VSI_NN_OP_ADD, 2, 1, 36);

    /*-----------------------------------------
      lid       - Conv_Conv_128_60
      var       - node[90]
      name      - Conv_Conv_128
      operation - convolution
      input     - [50, 50, 64, 1]
      filter    - [3, 3, 64, 64]
      output    - [50, 50, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[90], VSI_NN_OP_CONV2D, 3, 1, 60);
    node[90]->nn_param.conv2d.ksize[0] = 3;
    node[90]->nn_param.conv2d.ksize[1] = 3;
    node[90]->nn_param.conv2d.weights = 64;
    node[90]->nn_param.conv2d.stride[0] = 1;
    node[90]->nn_param.conv2d.stride[1] = 1;
    node[90]->nn_param.conv2d.pad[0] = 1;
    node[90]->nn_param.conv2d.pad[1] = 1;
    node[90]->nn_param.conv2d.pad[2] = 1;
    node[90]->nn_param.conv2d.pad[3] = 1;
    node[90]->nn_param.conv2d.group = 1;
    node[90]->nn_param.conv2d.dilation[0] = 1;
    node[90]->nn_param.conv2d.dilation[1] = 1;
    node[90]->nn_param.conv2d.multiplier = 0;
    node[90]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[90]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[90]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Conv_Conv_33_10
      var       - node[91]
      name      - Conv_Conv_33
      operation - convolution
      input     - [512, 512, 96, 1]
      filter    - [3, 3, 96, 3]
      output    - [512, 512, 3, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[91], VSI_NN_OP_CONV2D, 3, 1, 10);
    node[91]->nn_param.conv2d.ksize[0] = 3;
    node[91]->nn_param.conv2d.ksize[1] = 3;
    node[91]->nn_param.conv2d.weights = 3;
    node[91]->nn_param.conv2d.stride[0] = 1;
    node[91]->nn_param.conv2d.stride[1] = 1;
    node[91]->nn_param.conv2d.pad[0] = 1;
    node[91]->nn_param.conv2d.pad[1] = 1;
    node[91]->nn_param.conv2d.pad[2] = 1;
    node[91]->nn_param.conv2d.pad[3] = 1;
    node[91]->nn_param.conv2d.group = 1;
    node[91]->nn_param.conv2d.dilation[0] = 1;
    node[91]->nn_param.conv2d.dilation[1] = 1;
    node[91]->nn_param.conv2d.multiplier = 0;
    node[91]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[91]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[91]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Concat_Concat_108_22
      var       - node[92]
      name      - Concat_Concat_108
      operation - concat
      input     - [128, 128, 64, 1]
                  [128, 128, 32, 1]
      output    - [128, 128, 96, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[92], VSI_NN_OP_CONCAT, 2, 1, 22);
    node[92]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - Relu_Relu_55_24
      var       - node[93]
      name      - Relu_Relu_55
      operation - relu
      input     - [200, 200, 64, 1]
      output    - [200, 200, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[93], VSI_NN_OP_RELU, 1, 1, 24);

    /*-----------------------------------------
      lid       - Add_Add_130_42
      var       - node[94]
      name      - Add_Add_130
      operation - add
      input     - [50, 50, 64, 1]
                  [50, 50, 64, 1]
      output    - [50, 50, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[94], VSI_NN_OP_ADD, 2, 1, 42);

    /*-----------------------------------------
      lid       - Mul_Mul_69_59
      var       - node[95]
      name      - Mul_Mul_69
      operation - multiply
      input     - [512, 512, 3, 1]
                  [512, 512, 3, 1]
      output    - [512, 512, 3, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[95], VSI_NN_OP_MULTIPLY, 2, 1, 59);
    node[95]->nn_param.multiply.scale = 1;
    node[95]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[95]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;

    /*-----------------------------------------
      lid       - Conv_Conv_109_14
      var       - node[96]
      name      - Conv_Conv_109
      operation - convolution
      input     - [128, 128, 96, 1]
      filter    - [3, 3, 96, 3]
      output    - [128, 128, 3, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[96], VSI_NN_OP_CONV2D, 3, 1, 14);
    node[96]->nn_param.conv2d.ksize[0] = 3;
    node[96]->nn_param.conv2d.ksize[1] = 3;
    node[96]->nn_param.conv2d.weights = 3;
    node[96]->nn_param.conv2d.stride[0] = 1;
    node[96]->nn_param.conv2d.stride[1] = 1;
    node[96]->nn_param.conv2d.pad[0] = 1;
    node[96]->nn_param.conv2d.pad[1] = 1;
    node[96]->nn_param.conv2d.pad[2] = 1;
    node[96]->nn_param.conv2d.pad[3] = 1;
    node[96]->nn_param.conv2d.group = 1;
    node[96]->nn_param.conv2d.dilation[0] = 1;
    node[96]->nn_param.conv2d.dilation[1] = 1;
    node[96]->nn_param.conv2d.multiplier = 0;
    node[96]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[96]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[96]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Concat_Concat_56_16
      var       - node[97]
      name      - Concat_Concat_56
      operation - concat
      input     - [200, 200, 64, 1]
                  [200, 200, 32, 1]
      output    - [200, 200, 96, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[97], VSI_NN_OP_CONCAT, 2, 1, 16);
    node[97]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - Relu_Relu_131_30
      var       - node[98]
      name      - Relu_Relu_131
      operation - relu
      input     - [50, 50, 64, 1]
      output    - [50, 50, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[98], VSI_NN_OP_RELU, 1, 1, 30);

    /*-----------------------------------------
      lid       - ReduceSum_ReduceSum_71_58
      var       - node[99]
      name      - ReduceSum_ReduceSum_71
      operation - reducesum
      input     - [512, 512, 3, 1]
      output    - [512, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[99], VSI_NN_OP_REDUCE, 1, 1, 58);
    node[99]->nn_param.reduce.type = VSI_NN_REDUCE_SUM;
    node[99]->nn_param.reduce.axis = axis_1;
    node[99]->nn_param.reduce.axis_num = 1;
    node[99]->nn_param.reduce.keep_dim = FALSE;

    /*-----------------------------------------
      lid       - Mul_Mul_145_71
      var       - node[100]
      name      - Mul_Mul_145
      operation - multiply
      input     - [128, 128, 3, 1]
                  [128, 128, 3, 1]
      output    - [128, 128, 3, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[100], VSI_NN_OP_MULTIPLY, 2, 1, 71);
    node[100]->nn_param.multiply.scale = 1;
    node[100]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[100]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;

    /*-----------------------------------------
      lid       - Conv_Conv_57_8
      var       - node[101]
      name      - Conv_Conv_57
      operation - convolution
      input     - [200, 200, 96, 1]
      filter    - [3, 3, 96, 3]
      output    - [200, 200, 3, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[101], VSI_NN_OP_CONV2D, 3, 1, 8);
    node[101]->nn_param.conv2d.ksize[0] = 3;
    node[101]->nn_param.conv2d.ksize[1] = 3;
    node[101]->nn_param.conv2d.weights = 3;
    node[101]->nn_param.conv2d.stride[0] = 1;
    node[101]->nn_param.conv2d.stride[1] = 1;
    node[101]->nn_param.conv2d.pad[0] = 1;
    node[101]->nn_param.conv2d.pad[1] = 1;
    node[101]->nn_param.conv2d.pad[2] = 1;
    node[101]->nn_param.conv2d.pad[3] = 1;
    node[101]->nn_param.conv2d.group = 1;
    node[101]->nn_param.conv2d.dilation[0] = 1;
    node[101]->nn_param.conv2d.dilation[1] = 1;
    node[101]->nn_param.conv2d.multiplier = 0;
    node[101]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[101]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[101]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Concat_Concat_132_20
      var       - node[102]
      name      - Concat_Concat_132
      operation - concat
      input     - [50, 50, 64, 1]
                  [50, 50, 32, 1]
      output    - [50, 50, 96, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[102], VSI_NN_OP_CONCAT, 2, 1, 20);
    node[102]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - Add_Add_73_41
      var       - node[103]
      name      - Add_Add_73
      operation - add
      input     - [512, 512, 1]
                  [1]
      output    - [512, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[103], VSI_NN_OP_ADD, 2, 1, 41);

    /*-----------------------------------------
      lid       - ReduceSum_ReduceSum_147_70
      var       - node[104]
      name      - ReduceSum_ReduceSum_147
      operation - reducesum
      input     - [128, 128, 3, 1]
      output    - [128, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[104], VSI_NN_OP_REDUCE, 1, 1, 70);
    node[104]->nn_param.reduce.type = VSI_NN_REDUCE_SUM;
    node[104]->nn_param.reduce.axis = axis_2;
    node[104]->nn_param.reduce.axis_num = 1;
    node[104]->nn_param.reduce.keep_dim = FALSE;

    /*-----------------------------------------
      lid       - Mul_Mul_58_76
      var       - node[105]
      name      - Mul_Mul_58
      operation - multiply
      input     - [200, 200, 3, 1]
                  [200, 200, 3, 1]
      output    - [200, 200, 3, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[105], VSI_NN_OP_MULTIPLY, 2, 1, 76);
    node[105]->nn_param.multiply.scale = 1;
    node[105]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[105]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;

    /*-----------------------------------------
      lid       - Conv_Conv_133_12
      var       - node[106]
      name      - Conv_Conv_133
      operation - convolution
      input     - [50, 50, 96, 1]
      filter    - [3, 3, 96, 3]
      output    - [50, 50, 3, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[106], VSI_NN_OP_CONV2D, 3, 1, 12);
    node[106]->nn_param.conv2d.ksize[0] = 3;
    node[106]->nn_param.conv2d.ksize[1] = 3;
    node[106]->nn_param.conv2d.weights = 3;
    node[106]->nn_param.conv2d.stride[0] = 1;
    node[106]->nn_param.conv2d.stride[1] = 1;
    node[106]->nn_param.conv2d.pad[0] = 1;
    node[106]->nn_param.conv2d.pad[1] = 1;
    node[106]->nn_param.conv2d.pad[2] = 1;
    node[106]->nn_param.conv2d.pad[3] = 1;
    node[106]->nn_param.conv2d.group = 1;
    node[106]->nn_param.conv2d.dilation[0] = 1;
    node[106]->nn_param.conv2d.dilation[1] = 1;
    node[106]->nn_param.conv2d.multiplier = 0;
    node[106]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[106]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[106]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sqrt_Sqrt_74_29
      var       - node[107]
      name      - Sqrt_Sqrt_74
      operation - sqrt
      input     - [512, 512, 1]
      output    - [512, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[107], VSI_NN_OP_SQRT, 1, 1, 29);

    /*-----------------------------------------
      lid       - Add_Add_149_47
      var       - node[108]
      name      - Add_Add_149
      operation - add
      input     - [128, 128, 1]
                  [1]
      output    - [128, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[108], VSI_NN_OP_ADD, 2, 1, 47);

    /*-----------------------------------------
      lid       - ReduceSum_ReduceSum_60_52
      var       - node[109]
      name      - ReduceSum_ReduceSum_60
      operation - reducesum
      input     - [200, 200, 3, 1]
      output    - [200, 200, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[109], VSI_NN_OP_REDUCE, 1, 1, 52);
    node[109]->nn_param.reduce.type = VSI_NN_REDUCE_SUM;
    node[109]->nn_param.reduce.axis = axis_3;
    node[109]->nn_param.reduce.axis_num = 1;
    node[109]->nn_param.reduce.keep_dim = FALSE;

    /*-----------------------------------------
      lid       - Mul_Mul_134_65
      var       - node[110]
      name      - Mul_Mul_134
      operation - multiply
      input     - [50, 50, 3, 1]
                  [50, 50, 3, 1]
      output    - [50, 50, 3, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[110], VSI_NN_OP_MULTIPLY, 2, 1, 65);
    node[110]->nn_param.multiply.scale = 1;
    node[110]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[110]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;

    /*-----------------------------------------
      lid       - Unsqueeze_Unsqueeze_76_19
      var       - node[111]
      name      - Unsqueeze_Unsqueeze_76
      operation - reshape
      input     - [512, 512, 1]
      output    - [512, 512, 1, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[111], VSI_NN_OP_RESHAPE, 1, 1, 19);
    node[111]->nn_param.reshape.size = shape_1;
    node[111]->nn_param.reshape.dim_num = 4;

    /*-----------------------------------------
      lid       - Sqrt_Sqrt_150_35
      var       - node[112]
      name      - Sqrt_Sqrt_150
      operation - sqrt
      input     - [128, 128, 1]
      output    - [128, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[112], VSI_NN_OP_SQRT, 1, 1, 35);

    /*-----------------------------------------
      lid       - Add_Add_62_38
      var       - node[113]
      name      - Add_Add_62
      operation - add
      input     - [200, 200, 1]
                  [1]
      output    - [200, 200, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[113], VSI_NN_OP_ADD, 2, 1, 38);

    /*-----------------------------------------
      lid       - ReduceSum_ReduceSum_136_64
      var       - node[114]
      name      - ReduceSum_ReduceSum_136
      operation - reducesum
      input     - [50, 50, 3, 1]
      output    - [50, 50, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[114], VSI_NN_OP_REDUCE, 1, 1, 64);
    node[114]->nn_param.reduce.type = VSI_NN_REDUCE_SUM;
    node[114]->nn_param.reduce.axis = axis_4;
    node[114]->nn_param.reduce.axis_num = 1;
    node[114]->nn_param.reduce.keep_dim = FALSE;

    /*-----------------------------------------
      lid       - Div_Div_79_5
      var       - node[115]
      name      - Div_Div_79
      operation - real_div
      input     - [512, 512, 3, 1]
                  [512, 512, 1, 1]
      output    - [512, 512, 3, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[115], VSI_NN_OP_DIVIDE, 2, 1, 5);
    node[115]->nn_param.divide.scale = 1;
    node[115]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[115]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;

    /*-----------------------------------------
      lid       - Unsqueeze_Unsqueeze_152_23
      var       - node[116]
      name      - Unsqueeze_Unsqueeze_152
      operation - reshape
      input     - [128, 128, 1]
      output    - [128, 128, 1, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[116], VSI_NN_OP_RESHAPE, 1, 1, 23);
    node[116]->nn_param.reshape.size = shape_2;
    node[116]->nn_param.reshape.dim_num = 4;

    /*-----------------------------------------
      lid       - Sqrt_Sqrt_63_26
      var       - node[117]
      name      - Sqrt_Sqrt_63
      operation - sqrt
      input     - [200, 200, 1]
      output    - [200, 200, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[117], VSI_NN_OP_SQRT, 1, 1, 26);

    /*-----------------------------------------
      lid       - Add_Add_138_44
      var       - node[118]
      name      - Add_Add_138
      operation - add
      input     - [50, 50, 1]
                  [1]
      output    - [50, 50, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[118], VSI_NN_OP_ADD, 2, 1, 44);

    /*-----------------------------------------
      lid       - Div_Div_155_7
      var       - node[119]
      name      - Div_Div_155
      operation - real_div
      input     - [128, 128, 3, 1]
                  [128, 128, 1, 1]
      output    - [128, 128, 3, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[119], VSI_NN_OP_DIVIDE, 2, 1, 7);
    node[119]->nn_param.divide.scale = 1;
    node[119]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[119]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;

    /*-----------------------------------------
      lid       - Unsqueeze_Unsqueeze_65_17
      var       - node[120]
      name      - Unsqueeze_Unsqueeze_65
      operation - reshape
      input     - [200, 200, 1]
      output    - [200, 200, 1, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[120], VSI_NN_OP_RESHAPE, 1, 1, 17);
    node[120]->nn_param.reshape.size = shape_3;
    node[120]->nn_param.reshape.dim_num = 4;

    /*-----------------------------------------
      lid       - Sqrt_Sqrt_139_32
      var       - node[121]
      name      - Sqrt_Sqrt_139
      operation - sqrt
      input     - [50, 50, 1]
      output    - [50, 50, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[121], VSI_NN_OP_SQRT, 1, 1, 32);

    /*-----------------------------------------
      lid       - Div_Div_68_4
      var       - node[122]
      name      - Div_Div_68
      operation - real_div
      input     - [200, 200, 3, 1]
                  [200, 200, 1, 1]
      output    - [200, 200, 3, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[122], VSI_NN_OP_DIVIDE, 2, 1, 4);
    node[122]->nn_param.divide.scale = 1;
    node[122]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[122]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;

    /*-----------------------------------------
      lid       - Unsqueeze_Unsqueeze_141_21
      var       - node[123]
      name      - Unsqueeze_Unsqueeze_141
      operation - reshape
      input     - [50, 50, 1]
      output    - [50, 50, 1, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[123], VSI_NN_OP_RESHAPE, 1, 1, 21);
    node[123]->nn_param.reshape.size = shape_4;
    node[123]->nn_param.reshape.dim_num = 4;

    /*-----------------------------------------
      lid       - Div_Div_144_6
      var       - node[124]
      name      - Div_Div_144
      operation - real_div
      input     - [50, 50, 3, 1]
                  [50, 50, 1, 1]
      output    - [50, 50, 3, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[124], VSI_NN_OP_DIVIDE, 2, 1, 6);
    node[124]->nn_param.divide.scale = 1;
    node[124]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[124]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;

    }
    else
    {
    NEW_VXNODE(node[0], VSI_NN_OP_NBG, 2, 4, 0);
    node[0]->nn_param.nbg.type = VSI_NN_NBG_FILE;
    node[0]->nn_param.nbg.url = data_file_name;

    }

/*-----------------------------------------
  Tensor initialize
 -----------------------------------------*/
    attr.dtype.fmt = VSI_NN_DIM_FMT_NCHW;
    /* @attach_Div_Div_155/out0_0:out0 */
    attr.size[0] = 128;
    attr.size[1] = 128;
    attr.size[2] = 3;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_NORM_TENSOR(norm_tensor[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @attach_Div_Div_144/out0_1:out0 */
    attr.size[0] = 50;
    attr.size[1] = 50;
    attr.size[2] = 3;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_NORM_TENSOR(norm_tensor[1], attr, VSI_NN_TYPE_FLOAT16);

    /* @attach_Div_Div_79/out0_2:out0 */
    attr.size[0] = 512;
    attr.size[1] = 512;
    attr.size[2] = 3;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_NORM_TENSOR(norm_tensor[2], attr, VSI_NN_TYPE_FLOAT16);

    /* @attach_Div_Div_68/out0_3:out0 */
    attr.size[0] = 200;
    attr.size[1] = 200;
    attr.size[2] = 3;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_NORM_TENSOR(norm_tensor[3], attr, VSI_NN_TYPE_FLOAT16);

    /* @input_ref_133:out0 */
    attr.size[0] = 512;
    attr.size[1] = 512;
    attr.size[2] = 1;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.scale = 1.0;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_NORM_TENSOR(norm_tensor[4], attr, VSI_NN_TYPE_UINT8);

    /* @input_t_134:out0 */
    attr.size[0] = 800;
    attr.size[1] = 800;
    attr.size[2] = 1;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.scale = 1.0;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_NORM_TENSOR(norm_tensor[5], attr, VSI_NN_TYPE_UINT8);



    if( !inference_with_nbg )
    {
    /* @Initializer_217_53:data */
    attr.size[0] = 1;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[0], attr, VSI_NN_TYPE_FLOAT16, 265392, 2);

    /* @Conv_Conv_10_80:weight
       @Conv_Conv_86_92:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 1;
    attr.size[3] = 32;
    attr.dim_num = 4;
    attr.dtype.scale = 0.00035122252302244306;
    attr.dtype.zero_point = 124;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[1], attr, VSI_NN_TYPE_UINT8, 75116, 288);

    /* @Conv_Conv_10_80:bias */
    attr.size[0] = 32;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00035122252302244306;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[2], attr, VSI_NN_TYPE_INT32, 74988, 128);

    /* @Conv_Conv_86_92:bias */
    attr.size[0] = 32;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00034683224567156126;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[3], attr, VSI_NN_TYPE_INT32, 264432, 128);

    /* @Conv_Conv_12_81:weight
       @Conv_Conv_88_94:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 32;
    attr.size[3] = 32;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0028274564538151026;
    attr.dtype.zero_point = 106;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[4], attr, VSI_NN_TYPE_UINT8, 203692, 9216);

    /* @Conv_Conv_12_81:bias */
    attr.size[0] = 32;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00014365933876495443;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[5], attr, VSI_NN_TYPE_INT32, 203564, 128);

    /* @Conv_Conv_34_75:weight
       @Conv_Conv_110_86:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 1;
    attr.size[3] = 32;
    attr.dim_num = 4;
    attr.dtype.scale = 0.00039078632835298777;
    attr.dtype.zero_point = 105;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[6], attr, VSI_NN_TYPE_UINT8, 75532, 288);

    /* @Conv_Conv_34_75:bias */
    attr.size[0] = 32;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00039078632835298777;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[7], attr, VSI_NN_TYPE_INT32, 262500, 128);

    /* @Conv_Conv_88_94:bias */
    attr.size[0] = 32;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00012006946941221872;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[8], attr, VSI_NN_TYPE_INT32, 264560, 128);

    /* @Conv_Conv_110_86:bias */
    attr.size[0] = 32;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00030209315914585255;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[9], attr, VSI_NN_TYPE_INT32, 75404, 128);

    /* @Conv_Conv_14_56:weight
       @Conv_Conv_90_68:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 32;
    attr.size[3] = 32;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0022725961171090603;
    attr.dtype.zero_point = 110;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[10], attr, VSI_NN_TYPE_UINT8, 215640, 9216);

    /* @Conv_Conv_14_56:bias */
    attr.size[0] = 32;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00010327365792942543;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[11], attr, VSI_NN_TYPE_INT32, 215512, 128);

    /* @Conv_Conv_36_97:weight
       @Conv_Conv_112_105:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 32;
    attr.size[3] = 32;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0023089947644621134;
    attr.dtype.zero_point = 125;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[12], attr, VSI_NN_TYPE_UINT8, 75948, 9216);

    /* @Conv_Conv_36_97:bias */
    attr.size[0] = 32;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00014547245282690337;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[13], attr, VSI_NN_TYPE_INT32, 262628, 128);

    /* @Conv_Conv_90_68:bias */
    attr.size[0] = 32;
    attr.dim_num = 1;
    attr.dtype.scale = 9.444842960493367e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[14], attr, VSI_NN_TYPE_INT32, 264688, 128);

    /* @Conv_Conv_112_105:bias */
    attr.size[0] = 32;
    attr.dim_num = 1;
    attr.dtype.scale = 7.36883803139311e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[15], attr, VSI_NN_TYPE_INT32, 75820, 128);

    /* @Conv_Conv_38_50:weight
       @Conv_Conv_114_62:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 32;
    attr.size[3] = 32;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0024035789538174868;
    attr.dtype.zero_point = 118;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[16], attr, VSI_NN_TYPE_UINT8, 85292, 9216);

    /* @Conv_Conv_38_50:bias */
    attr.size[0] = 32;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0001863456537813859;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[17], attr, VSI_NN_TYPE_INT32, 262756, 128);

    /* @Conv_Conv_20_116:weight
       @Conv_Conv_96_128:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 32;
    attr.size[3] = 48;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0037557119503617287;
    attr.dtype.zero_point = 146;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[18], attr, VSI_NN_TYPE_UINT8, 259992, 1536);

    /* @Conv_Conv_20_116:bias */
    attr.size[0] = 48;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00019510768365793227;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[19], attr, VSI_NN_TYPE_INT32, 259800, 192);

    /* @Conv_Conv_17_130:weight
       @Conv_Conv_93_132:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 32;
    attr.size[3] = 48;
    attr.dim_num = 4;
    attr.dtype.scale = 0.002639126032590866;
    attr.dtype.zero_point = 120;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[20], attr, VSI_NN_TYPE_UINT8, 225048, 13824);

    /* @Conv_Conv_17_130:bias */
    attr.size[0] = 48;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0001371015066931741;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[21], attr, VSI_NN_TYPE_INT32, 224856, 192);

    /* @Conv_Conv_114_62:bias */
    attr.size[0] = 32;
    attr.dim_num = 1;
    attr.dtype.scale = 7.611532037697481e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[22], attr, VSI_NN_TYPE_INT32, 85164, 128);

    /* @Conv_Conv_96_128:bias */
    attr.size[0] = 48;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0001983168122401957;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[23], attr, VSI_NN_TYPE_INT32, 265200, 192);

    /* @Conv_Conv_93_132:bias */
    attr.size[0] = 48;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00013935655044927664;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[24], attr, VSI_NN_TYPE_INT32, 264816, 192);

    /* @Conv_Conv_19_123:weight
       @Conv_Conv_95_127:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 48;
    attr.size[3] = 48;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0021154244896024466;
    attr.dtype.zero_point = 120;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[25], attr, VSI_NN_TYPE_UINT8, 239064, 20736);

    /* @Conv_Conv_19_123:bias */
    attr.size[0] = 48;
    attr.dim_num = 1;
    attr.dtype.scale = 9.209659248327496e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[26], attr, VSI_NN_TYPE_INT32, 238872, 192);

    /* @Conv_Conv_44_112:weight
       @Conv_Conv_120_120:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 32;
    attr.size[3] = 48;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0043060267344117165;
    attr.dtype.zero_point = 122;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[27], attr, VSI_NN_TYPE_UINT8, 129644, 1536);

    /* @Conv_Conv_44_112:bias */
    attr.size[0] = 48;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0003039579221870217;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[28], attr, VSI_NN_TYPE_INT32, 263268, 192);

    /* @Conv_Conv_41_122:weight
       @Conv_Conv_117_131:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 32;
    attr.size[3] = 48;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0023531836923211813;
    attr.dtype.zero_point = 107;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[29], attr, VSI_NN_TYPE_UINT8, 94700, 13824);

    /* @Conv_Conv_41_122:bias */
    attr.size[0] = 48;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00016610877492381597;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[30], attr, VSI_NN_TYPE_INT32, 262884, 192);

    /* @Conv_Conv_95_127:bias */
    attr.size[0] = 48;
    attr.dim_num = 1;
    attr.dtype.scale = 8.224201021293787e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[31], attr, VSI_NN_TYPE_INT32, 265008, 192);

    /* @Conv_Conv_120_120:bias */
    attr.size[0] = 48;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00014295171184333308;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[32], attr, VSI_NN_TYPE_INT32, 129452, 192);

    /* @Conv_Conv_117_131:bias */
    attr.size[0] = 48;
    attr.dim_num = 1;
    attr.dtype.scale = 7.812112136017322e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[33], attr, VSI_NN_TYPE_INT32, 94508, 192);

    /* @Conv_Conv_43_111:weight
       @Conv_Conv_119_125:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 48;
    attr.size[3] = 48;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0020956764928996563;
    attr.dtype.zero_point = 120;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[34], attr, VSI_NN_TYPE_UINT8, 108716, 20736);

    /* @Conv_Conv_43_111:bias */
    attr.size[0] = 48;
    attr.dim_num = 1;
    attr.dtype.scale = 8.867757241839795e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[35], attr, VSI_NN_TYPE_INT32, 263076, 192);

    /* @Conv_Conv_119_125:bias */
    attr.size[0] = 48;
    attr.dim_num = 1;
    attr.dtype.scale = 5.4703117879915594e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[36], attr, VSI_NN_TYPE_INT32, 108524, 192);

    /* @Conv_Conv_24_82:weight
       @Conv_Conv_100_108:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 80;
    attr.size[3] = 48;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0018994733691215515;
    attr.dtype.zero_point = 111;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[37], attr, VSI_NN_TYPE_UINT8, 192, 3840);

    /* @Conv_Conv_24_82:bias */
    attr.size[0] = 48;
    attr.dim_num = 1;
    attr.dtype.scale = 9.650974035035897e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[38], attr, VSI_NN_TYPE_INT32, 261528, 192);

    /* @Conv_Conv_100_108:bias */
    attr.size[0] = 48;
    attr.dim_num = 1;
    attr.dtype.scale = 8.066215813085087e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[39], attr, VSI_NN_TYPE_INT32, 0, 192);

    /* @Conv_Conv_29_55:weight
       @Conv_Conv_105_67:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 48;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.scale = 0.003598372219130397;
    attr.dtype.zero_point = 137;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[40], attr, VSI_NN_TYPE_UINT8, 69312, 3072);

    /* @Conv_Conv_29_55:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00016627813381105052;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[41], attr, VSI_NN_TYPE_INT32, 262232, 256);

    /* @Conv_Conv_26_101:weight
       @Conv_Conv_102_107:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 48;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.scale = 0.002242792397737503;
    attr.dtype.zero_point = 113;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[42], attr, VSI_NN_TYPE_UINT8, 4288, 27648);

    /* @Conv_Conv_26_101:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0001036377872302291;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[43], attr, VSI_NN_TYPE_INT32, 261720, 256);

    /* @Conv_Conv_48_96:weight
       @Conv_Conv_124_104:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 80;
    attr.size[3] = 48;
    attr.dim_num = 4;
    attr.dtype.scale = 0.002056785859167576;
    attr.dtype.zero_point = 116;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[44], attr, VSI_NN_TYPE_UINT8, 131372, 3840);

    /* @Conv_Conv_48_96:bias */
    attr.size[0] = 48;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00012958264483500792;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[45], attr, VSI_NN_TYPE_INT32, 263460, 192);

    /* @Conv_Conv_105_67:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 9.474452984594914e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[46], attr, VSI_NN_TYPE_INT32, 69056, 256);

    /* @Conv_Conv_102_107:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 5.905234320563446e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[47], attr, VSI_NN_TYPE_INT32, 4032, 256);

    /* @Conv_Conv_124_104:bias */
    attr.size[0] = 48;
    attr.dim_num = 1;
    attr.dtype.scale = 6.563948127875571e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[48], attr, VSI_NN_TYPE_INT32, 131180, 192);

    /* @Conv_Conv_28_54:weight
       @Conv_Conv_104_66:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 64;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0017758648609742522;
    attr.dtype.zero_point = 106;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[49], attr, VSI_NN_TYPE_UINT8, 32192, 36864);

    /* @Conv_Conv_28_54:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 8.057052803964052e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[50], attr, VSI_NN_TYPE_INT32, 261976, 256);

    /* @Conv_Conv_53_49:weight
       @Conv_Conv_129_61:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 48;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.scale = 0.003527164226397872;
    attr.dtype.zero_point = 132;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[51], attr, VSI_NN_TYPE_UINT8, 200492, 3072);

    /* @Conv_Conv_53_49:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00012847091944921153;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[52], attr, VSI_NN_TYPE_INT32, 264164, 256);

    /* @Conv_Conv_50_95:weight
       @Conv_Conv_126_103:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 48;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0018589391838759184;
    attr.dtype.zero_point = 115;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[53], attr, VSI_NN_TYPE_UINT8, 135468, 27648);

    /* @Conv_Conv_50_95:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 6.770867779995644e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[54], attr, VSI_NN_TYPE_INT32, 263652, 256);

    /* @Conv_Conv_104_66:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 5.4466103185455816e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[55], attr, VSI_NN_TYPE_INT32, 31936, 256);

    /* @Conv_Conv_129_61:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 4.526355378637573e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[56], attr, VSI_NN_TYPE_INT32, 200236, 256);

    /* @Conv_Conv_126_103:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 2.3855479454354617e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[57], attr, VSI_NN_TYPE_INT32, 135212, 256);

    /* @Conv_Conv_52_48:weight
       @Conv_Conv_128_60:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 64;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0014442476676777005;
    attr.dtype.zero_point = 117;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[58], attr, VSI_NN_TYPE_UINT8, 163372, 36864);

    /* @Conv_Conv_52_48:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 4.445290032828691e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[59], attr, VSI_NN_TYPE_INT32, 263908, 256);

    /* @Conv_Conv_128_60:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 1.988341403202649e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[60], attr, VSI_NN_TYPE_INT32, 163116, 256);

    /* @Conv_Conv_33_10:weight
       @Conv_Conv_109_14:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 96;
    attr.size[3] = 3;
    attr.dim_num = 4;
    attr.dtype.scale = 0.00020508341549430043;
    attr.dtype.zero_point = 141;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[61], attr, VSI_NN_TYPE_UINT8, 72396, 2592);

    /* @Conv_Conv_33_10:bias */
    attr.size[0] = 3;
    attr.dim_num = 1;
    attr.dtype.scale = 1.0653998677906168e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[62], attr, VSI_NN_TYPE_INT32, 262488, 12);

    /* @Conv_Conv_109_14:bias */
    attr.size[0] = 3;
    attr.dim_num = 1;
    attr.dtype.scale = 1.0829235506265057e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[63], attr, VSI_NN_TYPE_INT32, 72384, 12);

    /* @Conv_Conv_57_8:weight
       @Conv_Conv_133_12:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 96;
    attr.size[3] = 3;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0001860627089627087;
    attr.dtype.zero_point = 141;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[64], attr, VSI_NN_TYPE_UINT8, 212920, 2592);

    /* @Conv_Conv_57_8:bias */
    attr.size[0] = 3;
    attr.dim_num = 1;
    attr.dtype.scale = 1.3133971965578143e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[65], attr, VSI_NN_TYPE_INT32, 264420, 12);

    /* @Conv_Conv_133_12:bias */
    attr.size[0] = 3;
    attr.dim_num = 1;
    attr.dtype.scale = 6.176920023247571e-06;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[66], attr, VSI_NN_TYPE_INT32, 212908, 12);



    /* @Initializer_217_53:out0 */
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[0]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Conv_Conv_10_80:out0 */
    attr.dtype.scale = 0.10852884501218796;
    attr.dtype.zero_point = 146;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[1]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @AveragePool_AveragePool_85_93:out0 */
    attr.dtype.scale = 0.987500011920929;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[2]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Slice_Slice_4_106:out0 */
    attr.dtype.scale = 1.0;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[3]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @LeakyRelu_LeakyRelu_11_57:out0 */
    attr.dtype.scale = 0.050808683;
    attr.dtype.zero_point = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[4]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_86_92:out0 */
    attr.dtype.scale = 0.08774323016405106;
    attr.dtype.zero_point = 133;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[5]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Slice_Slice_9_88:out0 */
    attr.dtype.scale = 1.0;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[6]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_12_81:out0 */
    attr.dtype.scale = 0.045443031936883926;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[7]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @LeakyRelu_LeakyRelu_87_69:out0 */
    attr.dtype.scale = 0.04246554;
    attr.dtype.zero_point = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[8]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_34_75:out0 */
    attr.dtype.scale = 0.13854116201400757;
    attr.dtype.zero_point = 140;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[9]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @AveragePool_AveragePool_82_87:out0 */
    attr.dtype.scale = 0.7730392217636108;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[10]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Relu_Relu_13_79:out0 */
    attr.dtype.scale = 0.045443031936883926;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[11]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_88_94:out0 */
    attr.dtype.scale = 0.04155970737338066;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[12]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @LeakyRelu_LeakyRelu_35_51:out0 */
    attr.dtype.scale = 0.063002504;
    attr.dtype.zero_point = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[13]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_110_86:out0 */
    attr.dtype.scale = 0.06903521716594696;
    attr.dtype.zero_point = 139;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[14]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_14_56:out0 */
    attr.dtype.scale = 0.08226390182971954;
    attr.dtype.zero_point = 119;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[15]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Relu_Relu_89_91:out0 */
    attr.dtype.scale = 0.04155970737338066;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[16]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_36_97:out0 */
    attr.dtype.scale = 0.07752840965986252;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[17]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @LeakyRelu_LeakyRelu_111_63:out0 */
    attr.dtype.scale = 0.03191362;
    attr.dtype.zero_point = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[18]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Add_Add_15_40:out0 */
    attr.dtype.scale = 0.09026948362588882;
    attr.dtype.zero_point = 108;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[19]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_90_68:out0 */
    attr.dtype.scale = 0.06869406253099442;
    attr.dtype.zero_point = 120;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[20]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Relu_Relu_37_74:out0 */
    attr.dtype.scale = 0.07752840965986252;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[21]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_112_105:out0 */
    attr.dtype.scale = 0.03166749328374863;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[22]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Relu_Relu_16_28:out0 */
    attr.dtype.scale = 0.05194958671927452;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[23]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Add_Add_91_46:out0 */
    attr.dtype.scale = 0.08456447720527649;
    attr.dtype.zero_point = 96;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[24]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_38_50:out0 */
    attr.dtype.scale = 0.10823740065097809;
    attr.dtype.zero_point = 141;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[25]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Relu_Relu_113_85:out0 */
    attr.dtype.scale = 0.03166749328374863;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[26]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_20_116:out0 */
    attr.dtype.scale = 0.08832848817110062;
    attr.dtype.zero_point = 130;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[27]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_17_130:out0 */
    attr.dtype.scale = 0.0435357503592968;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[28]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Relu_Relu_92_34:out0 */
    attr.dtype.scale = 0.05280405282974243;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[29]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Add_Add_39_37:out0 */
    attr.dtype.scale = 0.12939657270908356;
    attr.dtype.zero_point = 116;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[30]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_114_62:out0 */
    attr.dtype.scale = 0.05087115243077278;
    attr.dtype.zero_point = 136;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[31]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Relu_Relu_18_124:out0 */
    attr.dtype.scale = 0.0435357503592968;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[32]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_96_128:out0 */
    attr.dtype.scale = 0.07629839330911636;
    attr.dtype.zero_point = 119;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[33]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_93_132:out0 */
    attr.dtype.scale = 0.03887730836868286;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[34]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Relu_Relu_40_25:out0 */
    attr.dtype.scale = 0.07058895379304886;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[35]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Add_Add_115_43:out0 */
    attr.dtype.scale = 0.06033012643456459;
    attr.dtype.zero_point = 115;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[36]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_19_123:out0 */
    attr.dtype.scale = 0.09034835547208786;
    attr.dtype.zero_point = 128;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[37]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Relu_Relu_94_129:out0 */
    attr.dtype.scale = 0.03887730836868286;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[38]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_44_112:out0 */
    attr.dtype.scale = 0.11665604263544083;
    attr.dtype.zero_point = 144;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[39]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_41_122:out0 */
    attr.dtype.scale = 0.04231453314423561;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[40]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Relu_Relu_116_31:out0 */
    attr.dtype.scale = 0.03319805487990379;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[41]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Add_Add_21_115:out0 */
    attr.dtype.scale = 0.09744560718536377;
    attr.dtype.zero_point = 124;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[42]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_95_127:out0 */
    attr.dtype.scale = 0.06667082756757736;
    attr.dtype.zero_point = 127;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[43]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Relu_Relu_42_113:out0 */
    attr.dtype.scale = 0.04231453314423561;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[44]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_120_120:out0 */
    attr.dtype.scale = 0.051324132829904556;
    attr.dtype.zero_point = 141;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[45]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_117_131:out0 */
    attr.dtype.scale = 0.02610284462571144;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[46]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Relu_Relu_22_114:out0 */
    attr.dtype.scale = 0.050808683037757874;
    attr.dtype.zero_point = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[47]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Add_Add_97_121:out0 */
    attr.dtype.scale = 0.0818408876657486;
    attr.dtype.zero_point = 125;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[48]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_43_111:out0 */
    attr.dtype.scale = 0.08367525041103363;
    attr.dtype.zero_point = 119;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[49]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Relu_Relu_118_126:out0 */
    attr.dtype.scale = 0.02610284462571144;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[50]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Concat_Concat_23_102:out0 */
    attr.dtype.scale = 0.050808683037757874;
    attr.dtype.zero_point = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[51]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Relu_Relu_98_110:out0 */
    attr.dtype.scale = 0.042465537786483765;
    attr.dtype.zero_point = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[52]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Add_Add_45_100:out0 */
    attr.dtype.scale = 0.12323539704084396;
    attr.dtype.zero_point = 157;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[53]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_119_125:out0 */
    attr.dtype.scale = 0.03643498942255974;
    attr.dtype.zero_point = 130;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[54]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_24_82:out0 */
    attr.dtype.scale = 0.09428497403860092;
    attr.dtype.zero_point = 131;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[55]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Concat_Concat_99_109:out0 */
    attr.dtype.scale = 0.042465537786483765;
    attr.dtype.zero_point = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[56]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Relu_Relu_46_99:out0 */
    attr.dtype.scale = 0.06300249695777893;
    attr.dtype.zero_point = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[57]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Add_Add_121_119:out0 */
    attr.dtype.scale = 0.05431829392910004;
    attr.dtype.zero_point = 142;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[58]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @LeakyRelu_LeakyRelu_25_78:out0 */
    attr.dtype.scale = 0.046209265;
    attr.dtype.zero_point = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[59]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_100_108:out0 */
    attr.dtype.scale = 0.053682874888181686;
    attr.dtype.zero_point = 131;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[60]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Concat_Concat_47_98:out0 */
    attr.dtype.scale = 0.06300249695777893;
    attr.dtype.zero_point = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[61]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Relu_Relu_122_118:out0 */
    attr.dtype.scale = 0.03191361948847771;
    attr.dtype.zero_point = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[62]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_29_55:out0 */
    attr.dtype.scale = 0.10393466055393219;
    attr.dtype.zero_point = 136;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[63]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_26_101:out0 */
    attr.dtype.scale = 0.04536974057555199;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[64]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @LeakyRelu_LeakyRelu_101_90:out0 */
    attr.dtype.scale = 0.02632983;
    attr.dtype.zero_point = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[65]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_48_96:out0 */
    attr.dtype.scale = 0.06680706888437271;
    attr.dtype.zero_point = 117;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[66]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Concat_Concat_123_117:out0 */
    attr.dtype.scale = 0.03191361948847771;
    attr.dtype.zero_point = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[67]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Relu_Relu_27_77:out0 */
    attr.dtype.scale = 0.04536974057555199;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[68]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_105_67:out0 */
    attr.dtype.scale = 0.06335830688476562;
    attr.dtype.zero_point = 136;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[69]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_102_107:out0 */
    attr.dtype.scale = 0.030670184642076492;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[70]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @LeakyRelu_LeakyRelu_49_73:out0 */
    attr.dtype.scale = 0.03642329;
    attr.dtype.zero_point = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[71]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_124_104:out0 */
    attr.dtype.scale = 0.02565981075167656;
    attr.dtype.zero_point = 129;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[72]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_28_54:out0 */
    attr.dtype.scale = 0.08237983286380768;
    attr.dtype.zero_point = 126;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[73]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Relu_Relu_103_89:out0 */
    attr.dtype.scale = 0.030670184642076492;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[74]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_53_49:out0 */
    attr.dtype.scale = 0.06854192167520523;
    attr.dtype.zero_point = 136;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[75]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_50_95:out0 */
    attr.dtype.scale = 0.0307792779058218;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[76]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @LeakyRelu_LeakyRelu_125_84:out0 */
    attr.dtype.scale = 0.012832846;
    attr.dtype.zero_point = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[77]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Add_Add_30_39:out0 */
    attr.dtype.scale = 0.10677128285169601;
    attr.dtype.zero_point = 145;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[78]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_104_66:out0 */
    attr.dtype.scale = 0.06036784499883652;
    attr.dtype.zero_point = 109;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[79]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Relu_Relu_51_72:out0 */
    attr.dtype.scale = 0.0307792779058218;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[80]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_129_61:out0 */
    attr.dtype.scale = 0.026934798806905746;
    attr.dtype.zero_point = 121;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[81]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_126_103:out0 */
    attr.dtype.scale = 0.01376731600612402;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[82]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Relu_Relu_31_27:out0 */
    attr.dtype.scale = 0.05194958671927452;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[83]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Add_Add_106_45:out0 */
    attr.dtype.scale = 0.08158780634403229;
    attr.dtype.zero_point = 113;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[84]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_52_48:out0 */
    attr.dtype.scale = 0.04827134683728218;
    attr.dtype.zero_point = 136;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[85]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Relu_Relu_127_83:out0 */
    attr.dtype.scale = 0.01376731600612402;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[86]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Concat_Concat_32_18:out0 */
    attr.dtype.scale = 0.05194958671927452;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[87]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Relu_Relu_107_33:out0 */
    attr.dtype.scale = 0.05280405282974243;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[88]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Add_Add_54_36:out0 */
    attr.dtype.scale = 0.07259048521518707;
    attr.dtype.zero_point = 144;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[89]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_128_60:out0 */
    attr.dtype.scale = 0.02780715748667717;
    attr.dtype.zero_point = 122;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[90]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_33_10:out0 */
    attr.dtype.scale = 0.09684156626462936;
    attr.dtype.zero_point = 108;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[91]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Concat_Concat_108_22:out0 */
    attr.dtype.scale = 0.05280405282974243;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[92]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Relu_Relu_55_24:out0 */
    attr.dtype.scale = 0.07058895379304886;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[93]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Add_Add_130_42:out0 */
    attr.dtype.scale = 0.034492384642362595;
    attr.dtype.zero_point = 119;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[94]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Mul_Mul_69_59:out0 */
    attr.dtype.scale = 0.7919852137565613;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[95]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_109_14:out0 */
    attr.dtype.scale = 0.05138304457068443;
    attr.dtype.zero_point = 102;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[96]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Concat_Concat_56_16:out0 */
    attr.dtype.scale = 0.07058895379304886;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[97]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Relu_Relu_131_30:out0 */
    attr.dtype.scale = 0.03319805487990379;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[98]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @ReduceSum_ReduceSum_71_58:out0 */
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[99]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Mul_Mul_145_71:out0 */
    attr.dtype.scale = 0.24254760146141052;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[100]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_57_8:out0 */
    attr.dtype.scale = 0.04277511313557625;
    attr.dtype.zero_point = 133;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[101]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Concat_Concat_132_20:out0 */
    attr.dtype.scale = 0.03319805487990379;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[102]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Add_Add_73_41:out0 */
    attr.dtype.scale = 1.0132033824920654;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[103]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @ReduceSum_ReduceSum_147_70:out0 */
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[104]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Mul_Mul_58_76:out0 */
    attr.dtype.scale = 0.12674109637737274;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[105]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_133_12:out0 */
    attr.dtype.scale = 0.030677761882543564;
    attr.dtype.zero_point = 152;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[106]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sqrt_Sqrt_74_29:out0 */
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[107]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_149_47:out0 */
    attr.dtype.scale = 0.330451101064682;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[108]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @ReduceSum_ReduceSum_60_52:out0 */
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[109]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Mul_Mul_134_65:out0 */
    attr.dtype.scale = 0.08487583696842194;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[110]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Unsqueeze_Unsqueeze_76_19:out0 */
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[111]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Sqrt_Sqrt_150_35:out0 */
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[112]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_62_38:out0 */
    attr.dtype.scale = 0.20050404965877533;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[113]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @ReduceSum_ReduceSum_136_64:out0 */
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[114]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Unsqueeze_Unsqueeze_152_23:out0 */
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[116]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Sqrt_Sqrt_63_26:out0 */
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[117]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Add_Add_138_44:out0 */
    attr.dtype.scale = 0.11121673882007599;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[118]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Unsqueeze_Unsqueeze_65_17:out0 */
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[120]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Sqrt_Sqrt_139_32:out0 */
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[121]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @Unsqueeze_Unsqueeze_141_21:out0 */
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[123]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);



/*-----------------------------------------
  Connection initialize
 -----------------------------------------*/
    node[1]->input.tensors[0] = norm_tensor[4];
    node[2]->input.tensors[0] = norm_tensor[4];
    node[3]->input.tensors[0] = norm_tensor[5];
    node[115]->output.tensors[0] = norm_tensor[2];
    node[119]->output.tensors[0] = norm_tensor[0];
    node[122]->output.tensors[0] = norm_tensor[3];
    node[124]->output.tensors[0] = norm_tensor[1];

    /* Initializer_217_53 */
    node[0]->input.tensors[0] = const_tensor[0]; /* data_data */

    /* Conv_Conv_10_80 */
    node[1]->input.tensors[1] = const_tensor[1]; /* data_weight */
    node[1]->input.tensors[2] = const_tensor[2]; /* data_bias */

    /* AveragePool_AveragePool_85_93 */

    /* Slice_Slice_4_106 */

    /* LeakyRelu_LeakyRelu_11_57 */
    node[4]->input.tensors[0] = node[1]->output.tensors[0];

    /* Conv_Conv_86_92 */
    node[5]->input.tensors[0] = node[2]->output.tensors[0];
    node[5]->input.tensors[1] = const_tensor[1]; /* data_weight */
    node[5]->input.tensors[2] = const_tensor[3]; /* data_bias */

    /* Slice_Slice_9_88 */
    node[6]->input.tensors[0] = node[3]->output.tensors[0];

    /* Conv_Conv_12_81 */
    node[7]->input.tensors[0] = node[4]->output.tensors[0];
    node[7]->input.tensors[1] = const_tensor[4]; /* data_weight */
    node[7]->input.tensors[2] = const_tensor[5]; /* data_bias */

    /* LeakyRelu_LeakyRelu_87_69 */
    node[8]->input.tensors[0] = node[5]->output.tensors[0];

    /* Conv_Conv_34_75 */
    node[9]->input.tensors[0] = node[6]->output.tensors[0];
    node[9]->input.tensors[1] = const_tensor[6]; /* data_weight */
    node[9]->input.tensors[2] = const_tensor[7]; /* data_bias */

    /* AveragePool_AveragePool_82_87 */
    node[10]->input.tensors[0] = node[6]->output.tensors[0];

    /* Relu_Relu_13_79 */
    node[11]->input.tensors[0] = node[7]->output.tensors[0];

    /* Conv_Conv_88_94 */
    node[12]->input.tensors[0] = node[8]->output.tensors[0];
    node[12]->input.tensors[1] = const_tensor[4]; /* data_weight */
    node[12]->input.tensors[2] = const_tensor[8]; /* data_bias */

    /* LeakyRelu_LeakyRelu_35_51 */
    node[13]->input.tensors[0] = node[9]->output.tensors[0];

    /* Conv_Conv_110_86 */
    node[14]->input.tensors[0] = node[10]->output.tensors[0];
    node[14]->input.tensors[1] = const_tensor[6]; /* data_weight */
    node[14]->input.tensors[2] = const_tensor[9]; /* data_bias */

    /* Conv_Conv_14_56 */
    node[15]->input.tensors[0] = node[11]->output.tensors[0];
    node[15]->input.tensors[1] = const_tensor[10]; /* data_weight */
    node[15]->input.tensors[2] = const_tensor[11]; /* data_bias */

    /* Relu_Relu_89_91 */
    node[16]->input.tensors[0] = node[12]->output.tensors[0];

    /* Conv_Conv_36_97 */
    node[17]->input.tensors[0] = node[13]->output.tensors[0];
    node[17]->input.tensors[1] = const_tensor[12]; /* data_weight */
    node[17]->input.tensors[2] = const_tensor[13]; /* data_bias */

    /* LeakyRelu_LeakyRelu_111_63 */
    node[18]->input.tensors[0] = node[14]->output.tensors[0];

    /* Add_Add_15_40 */
    node[19]->input.tensors[0] = node[15]->output.tensors[0];
    node[19]->input.tensors[1] = node[4]->output.tensors[0];

    /* Conv_Conv_90_68 */
    node[20]->input.tensors[0] = node[16]->output.tensors[0];
    node[20]->input.tensors[1] = const_tensor[10]; /* data_weight */
    node[20]->input.tensors[2] = const_tensor[14]; /* data_bias */

    /* Relu_Relu_37_74 */
    node[21]->input.tensors[0] = node[17]->output.tensors[0];

    /* Conv_Conv_112_105 */
    node[22]->input.tensors[0] = node[18]->output.tensors[0];
    node[22]->input.tensors[1] = const_tensor[12]; /* data_weight */
    node[22]->input.tensors[2] = const_tensor[15]; /* data_bias */

    /* Relu_Relu_16_28 */
    node[23]->input.tensors[0] = node[19]->output.tensors[0];

    /* Add_Add_91_46 */
    node[24]->input.tensors[0] = node[20]->output.tensors[0];
    node[24]->input.tensors[1] = node[8]->output.tensors[0];

    /* Conv_Conv_38_50 */
    node[25]->input.tensors[0] = node[21]->output.tensors[0];
    node[25]->input.tensors[1] = const_tensor[16]; /* data_weight */
    node[25]->input.tensors[2] = const_tensor[17]; /* data_bias */

    /* Relu_Relu_113_85 */
    node[26]->input.tensors[0] = node[22]->output.tensors[0];

    /* Conv_Conv_20_116 */
    node[27]->input.tensors[0] = node[23]->output.tensors[0];
    node[27]->input.tensors[1] = const_tensor[18]; /* data_weight */
    node[27]->input.tensors[2] = const_tensor[19]; /* data_bias */

    /* Conv_Conv_17_130 */
    node[28]->input.tensors[0] = node[23]->output.tensors[0];
    node[28]->input.tensors[1] = const_tensor[20]; /* data_weight */
    node[28]->input.tensors[2] = const_tensor[21]; /* data_bias */

    /* Relu_Relu_92_34 */
    node[29]->input.tensors[0] = node[24]->output.tensors[0];

    /* Add_Add_39_37 */
    node[30]->input.tensors[0] = node[25]->output.tensors[0];
    node[30]->input.tensors[1] = node[13]->output.tensors[0];

    /* Conv_Conv_114_62 */
    node[31]->input.tensors[0] = node[26]->output.tensors[0];
    node[31]->input.tensors[1] = const_tensor[16]; /* data_weight */
    node[31]->input.tensors[2] = const_tensor[22]; /* data_bias */

    /* Relu_Relu_18_124 */
    node[32]->input.tensors[0] = node[28]->output.tensors[0];

    /* Conv_Conv_96_128 */
    node[33]->input.tensors[0] = node[29]->output.tensors[0];
    node[33]->input.tensors[1] = const_tensor[18]; /* data_weight */
    node[33]->input.tensors[2] = const_tensor[23]; /* data_bias */

    /* Conv_Conv_93_132 */
    node[34]->input.tensors[0] = node[29]->output.tensors[0];
    node[34]->input.tensors[1] = const_tensor[20]; /* data_weight */
    node[34]->input.tensors[2] = const_tensor[24]; /* data_bias */

    /* Relu_Relu_40_25 */
    node[35]->input.tensors[0] = node[30]->output.tensors[0];

    /* Add_Add_115_43 */
    node[36]->input.tensors[0] = node[31]->output.tensors[0];
    node[36]->input.tensors[1] = node[18]->output.tensors[0];

    /* Conv_Conv_19_123 */
    node[37]->input.tensors[0] = node[32]->output.tensors[0];
    node[37]->input.tensors[1] = const_tensor[25]; /* data_weight */
    node[37]->input.tensors[2] = const_tensor[26]; /* data_bias */

    /* Relu_Relu_94_129 */
    node[38]->input.tensors[0] = node[34]->output.tensors[0];

    /* Conv_Conv_44_112 */
    node[39]->input.tensors[0] = node[35]->output.tensors[0];
    node[39]->input.tensors[1] = const_tensor[27]; /* data_weight */
    node[39]->input.tensors[2] = const_tensor[28]; /* data_bias */

    /* Conv_Conv_41_122 */
    node[40]->input.tensors[0] = node[35]->output.tensors[0];
    node[40]->input.tensors[1] = const_tensor[29]; /* data_weight */
    node[40]->input.tensors[2] = const_tensor[30]; /* data_bias */

    /* Relu_Relu_116_31 */
    node[41]->input.tensors[0] = node[36]->output.tensors[0];

    /* Add_Add_21_115 */
    node[42]->input.tensors[0] = node[37]->output.tensors[0];
    node[42]->input.tensors[1] = node[27]->output.tensors[0];

    /* Conv_Conv_95_127 */
    node[43]->input.tensors[0] = node[38]->output.tensors[0];
    node[43]->input.tensors[1] = const_tensor[25]; /* data_weight */
    node[43]->input.tensors[2] = const_tensor[31]; /* data_bias */

    /* Relu_Relu_42_113 */
    node[44]->input.tensors[0] = node[40]->output.tensors[0];

    /* Conv_Conv_120_120 */
    node[45]->input.tensors[0] = node[41]->output.tensors[0];
    node[45]->input.tensors[1] = const_tensor[27]; /* data_weight */
    node[45]->input.tensors[2] = const_tensor[32]; /* data_bias */

    /* Conv_Conv_117_131 */
    node[46]->input.tensors[0] = node[41]->output.tensors[0];
    node[46]->input.tensors[1] = const_tensor[29]; /* data_weight */
    node[46]->input.tensors[2] = const_tensor[33]; /* data_bias */

    /* Relu_Relu_22_114 */
    node[47]->input.tensors[0] = node[42]->output.tensors[0];

    /* Add_Add_97_121 */
    node[48]->input.tensors[0] = node[43]->output.tensors[0];
    node[48]->input.tensors[1] = node[33]->output.tensors[0];

    /* Conv_Conv_43_111 */
    node[49]->input.tensors[0] = node[44]->output.tensors[0];
    node[49]->input.tensors[1] = const_tensor[34]; /* data_weight */
    node[49]->input.tensors[2] = const_tensor[35]; /* data_bias */

    /* Relu_Relu_118_126 */
    node[50]->input.tensors[0] = node[46]->output.tensors[0];

    /* Concat_Concat_23_102 */
    node[51]->input.tensors[0] = node[47]->output.tensors[0];
    node[51]->input.tensors[1] = node[4]->output.tensors[0];

    /* Relu_Relu_98_110 */
    node[52]->input.tensors[0] = node[48]->output.tensors[0];

    /* Add_Add_45_100 */
    node[53]->input.tensors[0] = node[49]->output.tensors[0];
    node[53]->input.tensors[1] = node[39]->output.tensors[0];

    /* Conv_Conv_119_125 */
    node[54]->input.tensors[0] = node[50]->output.tensors[0];
    node[54]->input.tensors[1] = const_tensor[34]; /* data_weight */
    node[54]->input.tensors[2] = const_tensor[36]; /* data_bias */

    /* Conv_Conv_24_82 */
    node[55]->input.tensors[0] = node[51]->output.tensors[0];
    node[55]->input.tensors[1] = const_tensor[37]; /* data_weight */
    node[55]->input.tensors[2] = const_tensor[38]; /* data_bias */

    /* Concat_Concat_99_109 */
    node[56]->input.tensors[0] = node[52]->output.tensors[0];
    node[56]->input.tensors[1] = node[8]->output.tensors[0];

    /* Relu_Relu_46_99 */
    node[57]->input.tensors[0] = node[53]->output.tensors[0];

    /* Add_Add_121_119 */
    node[58]->input.tensors[0] = node[54]->output.tensors[0];
    node[58]->input.tensors[1] = node[45]->output.tensors[0];

    /* LeakyRelu_LeakyRelu_25_78 */
    node[59]->input.tensors[0] = node[55]->output.tensors[0];

    /* Conv_Conv_100_108 */
    node[60]->input.tensors[0] = node[56]->output.tensors[0];
    node[60]->input.tensors[1] = const_tensor[37]; /* data_weight */
    node[60]->input.tensors[2] = const_tensor[39]; /* data_bias */

    /* Concat_Concat_47_98 */
    node[61]->input.tensors[0] = node[57]->output.tensors[0];
    node[61]->input.tensors[1] = node[13]->output.tensors[0];

    /* Relu_Relu_122_118 */
    node[62]->input.tensors[0] = node[58]->output.tensors[0];

    /* Conv_Conv_29_55 */
    node[63]->input.tensors[0] = node[59]->output.tensors[0];
    node[63]->input.tensors[1] = const_tensor[40]; /* data_weight */
    node[63]->input.tensors[2] = const_tensor[41]; /* data_bias */

    /* Conv_Conv_26_101 */
    node[64]->input.tensors[0] = node[59]->output.tensors[0];
    node[64]->input.tensors[1] = const_tensor[42]; /* data_weight */
    node[64]->input.tensors[2] = const_tensor[43]; /* data_bias */

    /* LeakyRelu_LeakyRelu_101_90 */
    node[65]->input.tensors[0] = node[60]->output.tensors[0];

    /* Conv_Conv_48_96 */
    node[66]->input.tensors[0] = node[61]->output.tensors[0];
    node[66]->input.tensors[1] = const_tensor[44]; /* data_weight */
    node[66]->input.tensors[2] = const_tensor[45]; /* data_bias */

    /* Concat_Concat_123_117 */
    node[67]->input.tensors[0] = node[62]->output.tensors[0];
    node[67]->input.tensors[1] = node[18]->output.tensors[0];

    /* Relu_Relu_27_77 */
    node[68]->input.tensors[0] = node[64]->output.tensors[0];

    /* Conv_Conv_105_67 */
    node[69]->input.tensors[0] = node[65]->output.tensors[0];
    node[69]->input.tensors[1] = const_tensor[40]; /* data_weight */
    node[69]->input.tensors[2] = const_tensor[46]; /* data_bias */

    /* Conv_Conv_102_107 */
    node[70]->input.tensors[0] = node[65]->output.tensors[0];
    node[70]->input.tensors[1] = const_tensor[42]; /* data_weight */
    node[70]->input.tensors[2] = const_tensor[47]; /* data_bias */

    /* LeakyRelu_LeakyRelu_49_73 */
    node[71]->input.tensors[0] = node[66]->output.tensors[0];

    /* Conv_Conv_124_104 */
    node[72]->input.tensors[0] = node[67]->output.tensors[0];
    node[72]->input.tensors[1] = const_tensor[44]; /* data_weight */
    node[72]->input.tensors[2] = const_tensor[48]; /* data_bias */

    /* Conv_Conv_28_54 */
    node[73]->input.tensors[0] = node[68]->output.tensors[0];
    node[73]->input.tensors[1] = const_tensor[49]; /* data_weight */
    node[73]->input.tensors[2] = const_tensor[50]; /* data_bias */

    /* Relu_Relu_103_89 */
    node[74]->input.tensors[0] = node[70]->output.tensors[0];

    /* Conv_Conv_53_49 */
    node[75]->input.tensors[0] = node[71]->output.tensors[0];
    node[75]->input.tensors[1] = const_tensor[51]; /* data_weight */
    node[75]->input.tensors[2] = const_tensor[52]; /* data_bias */

    /* Conv_Conv_50_95 */
    node[76]->input.tensors[0] = node[71]->output.tensors[0];
    node[76]->input.tensors[1] = const_tensor[53]; /* data_weight */
    node[76]->input.tensors[2] = const_tensor[54]; /* data_bias */

    /* LeakyRelu_LeakyRelu_125_84 */
    node[77]->input.tensors[0] = node[72]->output.tensors[0];

    /* Add_Add_30_39 */
    node[78]->input.tensors[0] = node[73]->output.tensors[0];
    node[78]->input.tensors[1] = node[63]->output.tensors[0];

    /* Conv_Conv_104_66 */
    node[79]->input.tensors[0] = node[74]->output.tensors[0];
    node[79]->input.tensors[1] = const_tensor[49]; /* data_weight */
    node[79]->input.tensors[2] = const_tensor[55]; /* data_bias */

    /* Relu_Relu_51_72 */
    node[80]->input.tensors[0] = node[76]->output.tensors[0];

    /* Conv_Conv_129_61 */
    node[81]->input.tensors[0] = node[77]->output.tensors[0];
    node[81]->input.tensors[1] = const_tensor[51]; /* data_weight */
    node[81]->input.tensors[2] = const_tensor[56]; /* data_bias */

    /* Conv_Conv_126_103 */
    node[82]->input.tensors[0] = node[77]->output.tensors[0];
    node[82]->input.tensors[1] = const_tensor[53]; /* data_weight */
    node[82]->input.tensors[2] = const_tensor[57]; /* data_bias */

    /* Relu_Relu_31_27 */
    node[83]->input.tensors[0] = node[78]->output.tensors[0];

    /* Add_Add_106_45 */
    node[84]->input.tensors[0] = node[79]->output.tensors[0];
    node[84]->input.tensors[1] = node[69]->output.tensors[0];

    /* Conv_Conv_52_48 */
    node[85]->input.tensors[0] = node[80]->output.tensors[0];
    node[85]->input.tensors[1] = const_tensor[58]; /* data_weight */
    node[85]->input.tensors[2] = const_tensor[59]; /* data_bias */

    /* Relu_Relu_127_83 */
    node[86]->input.tensors[0] = node[82]->output.tensors[0];

    /* Concat_Concat_32_18 */
    node[87]->input.tensors[0] = node[83]->output.tensors[0];
    node[87]->input.tensors[1] = node[23]->output.tensors[0];

    /* Relu_Relu_107_33 */
    node[88]->input.tensors[0] = node[84]->output.tensors[0];

    /* Add_Add_54_36 */
    node[89]->input.tensors[0] = node[85]->output.tensors[0];
    node[89]->input.tensors[1] = node[75]->output.tensors[0];

    /* Conv_Conv_128_60 */
    node[90]->input.tensors[0] = node[86]->output.tensors[0];
    node[90]->input.tensors[1] = const_tensor[58]; /* data_weight */
    node[90]->input.tensors[2] = const_tensor[60]; /* data_bias */

    /* Conv_Conv_33_10 */
    node[91]->input.tensors[0] = node[87]->output.tensors[0];
    node[91]->input.tensors[1] = const_tensor[61]; /* data_weight */
    node[91]->input.tensors[2] = const_tensor[62]; /* data_bias */

    /* Concat_Concat_108_22 */
    node[92]->input.tensors[0] = node[88]->output.tensors[0];
    node[92]->input.tensors[1] = node[29]->output.tensors[0];

    /* Relu_Relu_55_24 */
    node[93]->input.tensors[0] = node[89]->output.tensors[0];

    /* Add_Add_130_42 */
    node[94]->input.tensors[0] = node[90]->output.tensors[0];
    node[94]->input.tensors[1] = node[81]->output.tensors[0];

    /* Mul_Mul_69_59 */
    node[95]->input.tensors[0] = node[91]->output.tensors[0];
    node[95]->input.tensors[1] = node[91]->output.tensors[0];
    node[95]->input.tensors[0] = node[91]->output.tensors[0];
    node[95]->input.tensors[1] = node[91]->output.tensors[0];

    /* Conv_Conv_109_14 */
    node[96]->input.tensors[0] = node[92]->output.tensors[0];
    node[96]->input.tensors[1] = const_tensor[61]; /* data_weight */
    node[96]->input.tensors[2] = const_tensor[63]; /* data_bias */

    /* Concat_Concat_56_16 */
    node[97]->input.tensors[0] = node[93]->output.tensors[0];
    node[97]->input.tensors[1] = node[35]->output.tensors[0];

    /* Relu_Relu_131_30 */
    node[98]->input.tensors[0] = node[94]->output.tensors[0];

    /* ReduceSum_ReduceSum_71_58 */
    node[99]->input.tensors[0] = node[95]->output.tensors[0];

    /* Mul_Mul_145_71 */
    node[100]->input.tensors[0] = node[96]->output.tensors[0];
    node[100]->input.tensors[1] = node[96]->output.tensors[0];
    node[100]->input.tensors[0] = node[96]->output.tensors[0];
    node[100]->input.tensors[1] = node[96]->output.tensors[0];

    /* Conv_Conv_57_8 */
    node[101]->input.tensors[0] = node[97]->output.tensors[0];
    node[101]->input.tensors[1] = const_tensor[64]; /* data_weight */
    node[101]->input.tensors[2] = const_tensor[65]; /* data_bias */

    /* Concat_Concat_132_20 */
    node[102]->input.tensors[0] = node[98]->output.tensors[0];
    node[102]->input.tensors[1] = node[41]->output.tensors[0];

    /* Add_Add_73_41 */
    node[103]->input.tensors[0] = node[99]->output.tensors[0];
    node[103]->input.tensors[1] = node[0]->output.tensors[0];

    /* ReduceSum_ReduceSum_147_70 */
    node[104]->input.tensors[0] = node[100]->output.tensors[0];

    /* Mul_Mul_58_76 */
    node[105]->input.tensors[0] = node[101]->output.tensors[0];
    node[105]->input.tensors[1] = node[101]->output.tensors[0];
    node[105]->input.tensors[0] = node[101]->output.tensors[0];
    node[105]->input.tensors[1] = node[101]->output.tensors[0];

    /* Conv_Conv_133_12 */
    node[106]->input.tensors[0] = node[102]->output.tensors[0];
    node[106]->input.tensors[1] = const_tensor[64]; /* data_weight */
    node[106]->input.tensors[2] = const_tensor[66]; /* data_bias */

    /* Sqrt_Sqrt_74_29 */
    node[107]->input.tensors[0] = node[103]->output.tensors[0];

    /* Add_Add_149_47 */
    node[108]->input.tensors[0] = node[104]->output.tensors[0];
    node[108]->input.tensors[1] = node[0]->output.tensors[0];

    /* ReduceSum_ReduceSum_60_52 */
    node[109]->input.tensors[0] = node[105]->output.tensors[0];

    /* Mul_Mul_134_65 */
    node[110]->input.tensors[0] = node[106]->output.tensors[0];
    node[110]->input.tensors[1] = node[106]->output.tensors[0];
    node[110]->input.tensors[0] = node[106]->output.tensors[0];
    node[110]->input.tensors[1] = node[106]->output.tensors[0];

    /* Unsqueeze_Unsqueeze_76_19 */
    node[111]->input.tensors[0] = node[107]->output.tensors[0];

    /* Sqrt_Sqrt_150_35 */
    node[112]->input.tensors[0] = node[108]->output.tensors[0];

    /* Add_Add_62_38 */
    node[113]->input.tensors[0] = node[109]->output.tensors[0];
    node[113]->input.tensors[1] = node[0]->output.tensors[0];

    /* ReduceSum_ReduceSum_136_64 */
    node[114]->input.tensors[0] = node[110]->output.tensors[0];

    /* Div_Div_79_5 */
    node[115]->input.tensors[0] = node[91]->output.tensors[0];
    node[115]->input.tensors[1] = node[111]->output.tensors[0];

    /* Unsqueeze_Unsqueeze_152_23 */
    node[116]->input.tensors[0] = node[112]->output.tensors[0];

    /* Sqrt_Sqrt_63_26 */
    node[117]->input.tensors[0] = node[113]->output.tensors[0];

    /* Add_Add_138_44 */
    node[118]->input.tensors[0] = node[114]->output.tensors[0];
    node[118]->input.tensors[1] = node[0]->output.tensors[0];

    /* Div_Div_155_7 */
    node[119]->input.tensors[0] = node[96]->output.tensors[0];
    node[119]->input.tensors[1] = node[116]->output.tensors[0];

    /* Unsqueeze_Unsqueeze_65_17 */
    node[120]->input.tensors[0] = node[117]->output.tensors[0];

    /* Sqrt_Sqrt_139_32 */
    node[121]->input.tensors[0] = node[118]->output.tensors[0];

    /* Div_Div_68_4 */
    node[122]->input.tensors[0] = node[101]->output.tensors[0];
    node[122]->input.tensors[1] = node[120]->output.tensors[0];

    /* Unsqueeze_Unsqueeze_141_21 */
    node[123]->input.tensors[0] = node[121]->output.tensors[0];

    /* Div_Div_144_6 */
    node[124]->input.tensors[0] = node[106]->output.tensors[0];
    node[124]->input.tensors[1] = node[123]->output.tensors[0];


    }
    else
    {
    node[0]->output.tensors[0] = norm_tensor[0];
    node[0]->output.tensors[1] = norm_tensor[1];
    node[0]->output.tensors[2] = norm_tensor[2];
    node[0]->output.tensors[3] = norm_tensor[3];
    node[0]->input.tensors[0] = norm_tensor[4];
    node[0]->input.tensors[1] = norm_tensor[5];

    }
    graph->output.tensors[0] = norm_tensor[0];
    graph->output.tensors[1] = norm_tensor[1];
    graph->output.tensors[2] = norm_tensor[2];
    graph->output.tensors[3] = norm_tensor[3];
    graph->input.tensors[0] = norm_tensor[4];
    graph->input.tensors[1] = norm_tensor[5];


    if( enable_pre_post_process )
    {
        sort = TRUE;
        if( pre_process_map_count > 0 )
        {
            for( i = 0; i < pre_process_map_count; i++ )
            {
                status = vsi_nn_AddGraphPreProcess(graph, pre_process_map[i].graph_input_idx,
                                                   pre_process_map[i].preprocesses,
                                                   pre_process_map[i].preprocess_count);
                TEST_CHECK_STATUS( status, error );
            }
        }

        if( post_process_map_count > 0 )
        {
            for( i = 0; i < post_process_map_count; i++ )
            {
                 status = vsi_nn_AddGraphPostProcess(graph, post_process_map[i].graph_output_idx,
                                                     post_process_map[i].postprocesses,
                                                     post_process_map[i].postprocess_count);
                 TEST_CHECK_STATUS( status, error );
            }
        }
    }

    status = vsi_nn_SetupGraph( graph, sort );
    TEST_CHECK_STATUS( status, error );
    vsi_nn_DumpGraphToJson( graph );

    if( VSI_FAILURE == status )
    {
        goto error;
    }

    fclose( fp );

    return graph;

error:
    if( NULL != fp )
    {
        fclose( fp );
    }

    release_ctx = ( NULL == in_ctx );
    vsi_nn_DumpGraphToJson( graph );
    vnn_ReleaseMatch0719Uint8( graph, release_ctx );

    return NULL;
} /* vsi_nn_CreateMatch0719Uint8() */

void vnn_ReleaseMatch0719Uint8
    (
    vsi_nn_graph_t * graph,
    vsi_bool release_ctx
    )
{
    vsi_nn_context_t ctx;
    if( NULL != graph )
    {
        ctx = graph->ctx;
        vsi_nn_ReleaseGraph( &graph );

        /*-----------------------------------------
        Unregister client ops
        -----------------------------------------*/
        

        if( release_ctx )
        {
            vsi_nn_ReleaseContext( &ctx );
        }
    }
} /* vsi_nn_ReleaseMatch0719Uint8() */

